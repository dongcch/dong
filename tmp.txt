服务端VoiceRecognizeWebSocketController.handleMessage实时接收
  在哪里配置，接收哪里来的数据？何时建立连接？afterConnectionEstablished调用时设置哪个连接？
VoiceRecognizeServiceImplIflyTek单线程处理？
RecordService.recordAsPcmContinuously方法中设定1秒一批
语音识别结果和声纹识别结果回调前端显示？哪里配置？
客户端集成了语音采集SDK和回调显示
服务端如何接收讯飞返回的结果？AsrServiceIflyTek.onMessage如何配置实现？
服务端与讯飞端是一个连接还是两个连接？
afterConnectionEstablished(WebSocketSession wsSession)中的wsSession是客户端与服务端的连接

VoiceRecognizeServiceImplIflyTek接收音频，如果超过5秒钟会不会退出线程？
哪里确定向讯飞发送的频率
语音识别、声纹识别顺序执行，两个识别的效率如何？通过队列，多个消费者共同进行，声纹识别后返回结果到队列

跟你确认下哈，客户他们测试的时候，服务端是部署在阿里云，客户端部署在他们本地，他们本地连阿里云是要走外网（互联网）的，上午你是说他们外网很差（连VPN会经常断）


ws://39.100.101.116:18013/websocket/test


沈阳航空航天大学
通信工程（543	561	550.6）
、信息与计算科学（	522	559	530.31）、
、探测制导与控制技术（526	557	539.58）、
能源与动力工程（530	570	544.9）
车辆工程（511	558	529.9）、
电子信息工程（545	575	554.19）

沈阳理工大学
通信工程（560	534	519	38292）
应用统计学（543	510	501	45498  47188）
物联网工程（542	514	505	43923）
电子信息工程（544	522	515	39865）
机械设计制造及其自动化（574	524	497）


探测制导与控制技术（550	514	490	50022）


信息与计算科学（558	530	520	37919）

机器人工程（555	542	533	33103）


辽宁工程技术大学
金融学（526	35664）
会计学（525	36051）
计算机科学与技术（448	67017）
通信工程（434	72618）
电子信息工程（436	71820）



发送一段时间后不再发送voice sent successfully, index=null（客户端与服务端出现延迟，超过5秒，线程退出；服务端与讯飞端出现错误，会导致ASR连接断开，无法再发送；应该增加重连机制）

从业务方面，介绍一下相关系统的功能，比如反欺诈系统，作用、目标、使用范围等等。


模型训练、特征提取一系列过程
训练方法演进过程

质监控相关文档

2019-07-05
与运营商资源或者优势结合
网络身份认证-反诈骗，风险防控
提供一个体验/演示的方式


@EnableTransactionManagement
@SpringBootApplication()
@ComponentScan(value = "com.ctbri.inquestSpeechServer", excludeFilters = @ComponentScan.Filter(type = FilterType.ASSIGNABLE_TYPE, classes = {
  AsrServiceIflyTek.class, AsrServiceIflyTekInnet.class }))
  
0.00390625
0.50781250

now1: 1562650886940
now1: 1562650887020
now1: 1562650887111
now1: 1562650887198
now1: 1562650887283
now1: 1562650887370
now1: 1562650887449
now1: 1562650887539
now1: 1562650887620
now1: 1562650887708
now1: 1562650887788
now1: 1562650887881
now1: 1562650887960
now1: 1562650888049
now1: 1562650888132
now1: 1562650888218
now1: 1562650888300


now1: 1562651061919
now2: 1562651061969
now1: 1562651062011
now2: 1562651062067
now1: 1562651062092
now2: 1562651062143
now1: 1562651062180
now2: 1562651062230
now1: 1562651062258
now2: 1562651062309
now1: 1562651062351
now2: 1562651062402
now1: 1562651062429
now2: 1562651062479
now1: 1562651062521
now2: 1562651062571
now1: 1562651062601
now2: 1562651062652
now1: 1562651062689
now2: 1562651062740
now1: 1562651062769
now2: 1562651062820
now1: 1562651062860
now2: 1562651062910
now1: 1562651062940
now2: 1562651062990
now1: 1562651063028
now2: 1562651063078
now1: 1562651063110
now2: 1562651063161
now1: 1562651063200
now2: 1562651063250
now1: 1562651063288
now2: 1562651063339



1. memory_profile_get_recog.log中第845行，内存由295.87890625增加到295.65234375，其他更多时候两次执行get_recognize_feature内存不变，只是方法内部会有增加
2189行，296.47656250 -> 296.50000000
2. memory_profile_return_results.log中1905行增加内存0.03515625m，到下一次循环没有完全被收回
5740行由297.55468750增加到297.78906250，5753行增加0.05468750m，5777行减少到297.81640625（减少了0.02734375m）
1498, 5642行增加0.01562500，下一次完全回收
5333行，内存减少0.01953125‬
5585行，内存减少0.01171875
其他很多时候增加0.01171875m，到下一次就能够收回



--unsafely-treat-insecure-origin-as-secure="http://39.100.101.116:18010" --user-data-dir=D:\tmp


1. 语义特征处理过程是在SemanticFeatureWorker中吗？具体语义特征逻辑是下载录音、识别录音（调研讯飞接口）、识别声纹？
2. 声纹特征处理过程是在VoiceprintFeatureWorker中吗？两个功能：声纹标注和声纹识别，声纹标注是根据起始截止时间截取音频，然后注册？
3. 呼叫特征、号码特征都没有具体实现？
4. controller中各个请求在哪里调用？



agent用于采集机器负载监控指标，每隔60秒push给Transfer，agent需要部署到所有要被监控的机器上
transfer是数据转发服务。它接收agent上报的数据，然后按照哈希规则进行数据分片、并将分片后的数据分别push给graph&judge等组件
graph是存储绘图数据的组件。graph组件 接收transfer组件推送上来的监控数据，同时处理api组件的查询请求、返回绘图数据。
api组件，提供统一的restAPI操作接口。比如：api组件接收查询请求，根据一致性哈希算法去相应的graph实例查询不同metric的数据，然后汇总拿到的数据，最后统一返回给用户。
Heartbeat Server心跳服务器，公司所有agent都会连到HBS，每分钟发一次心跳请求。用户配置了对某个机器80端口的监控，我们才会去采集这个机器80端口的存活性。那agent如何知道自己应该采集哪些端口和进程呢？向HBS要，HBS去读取Portal的数据库，返回给agent。
Judge用于告警判断，agent将数据push给Transfer，Transfer不但会转发给Graph组件来绘图，还会转发给Judge用于判断是否触发告警。Transfer通过一致性哈希来分片，每个Judge就只需要处理一小部分数据就可以了
alarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取处理，并进行不同渠道的发送。alarm是个单点,需要对alarm的存活做好监控？
nodata用于检测监控数据的上报异常；配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警
进程、端口监控，agent到底要采集哪些端口是通过用户配置的策略自动计算得出的，这个信息是通过agent和hbs的心跳机制下发的。
提供了一个通用jar包，只要引入这个jar包，就可以自动采集接口的调用次数、延迟时间等数据。然后将采集到的数据push给监控，一分钟push一次
上传业务数据注意tag（监控数据的属性标签）的使用



219.142.69.75 - - [18/Jul/2019:11:20:05 +0800] "GET /api/metric/query?query=dd&limit=10&_=1563419423796 HTTP/1.1" 500 291 "http://124.127.117.163:38081/portal/template/update/14" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"
219.142.69.75 - - [18/Jul/2019:11:20:06 +0800] "GET /api/metric/query?query=ddd&limit=10&_=1563419423797 HTTP/1.1" 500 291 "http://124.127.117.163:38081/portal/template/update/14" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"

NLP演进过程：self-attention, bert, xlnet
语音增强：GAN, SEGAN, WEBRTC, VAD

stream {
    server {
        listen 6030;
        proxy_connect_timeout 10s;
        proxy_timeout 6000s;
        proxy_pass 192.168.99.212:6030;
    }
}

19210283151358   210283200109051037

nohup /opt/open-falcon/agent/bin/falcon-agent -c /opt/open-falcon/agent/config/cfg.json >> /opt/open-falcon/agent/logs/agent.log 2>&1 &
nohup /opt/open-falcon/alarm/bin/falcon-alarm -c /opt/open-falcon/alarm/config/cfg.json >> /opt/open-falcon/alarm/logs/alarm.log 2>&1 &
德欣老师，系统级监控项这几个是可以直接用的（如果需要新增机器，把服务器连接信息告诉我，我去安装agent就可以），应用进程和端口这两项跟林悦老师沟通后可能暂时先不用监控；系统级监控项这部分您看还有其他想法吗？
暂时没有的话我想先这样，接下来打算着手研究研究日志收集和处理（包括如何不侵入代码收集日志等），为后续咱们运营、应用级别监控或者查找日志做些准备工作；期间如果有相对紧急的事情随时招呼我，优先解决紧急事情；
您看呢？


我们部门今年项目公司关闭情况整体比较顺利，上周和各个部门沟通，确定了亏损项目公司用注入资本的方式处理，现在已经草拟好了签报，准备下周提交；
项目公司主要分为马绍尔和香港两个地区，马绍尔公司已经大部分完成公司往来账户的清理工作，而且在去年也有相关经验，所以没什么问题；
现在主要padding在香港公司上，香港公司账户清理工作还没完成，而且它相对比较特殊，还需要进行税务申报，不过这块儿跟计财部同事沟通过，税务申报和账户清理工作可以同步进行，在这之后我们才能做项目关闭后续工作，我们肯定是争取今年完成项目关闭，所以还是希望计财同事帮忙尽快处理，越快越好，能在未来一周到两周完成是最好了；



1. 场景测试：
操作系统（win10，win7，xp），尽可能细化小版本
浏览器类型（chrome, firefox, 360极速, 360安全浏览器, IE），尽可能细化小版本
麦克风类型（640, 长麦克风, 笔记本自带）
输入采样频率（48k,44.1k,）
测试场景类型（男-男，男-女，女-女）
注册语音类型（相同文字录音, 不同文字录音, 短录音重复）
时间间隔长短
注册位置与麦克风距离、验证位置与麦克风距离
记录测试语音条数、错误条数
三人场景？模拟噪音？
提供注册样例短片；识别阶段样例短片；注册语音文字材料；
2. 功能测试：
开始验证-结束验证-开始验证-结束验证，是否能够正常结束
开始验证-开始验证-开始验证-结束验证，是否能够正常结束
开始验证-开始验证-开始验证-结束验证-结束验证，是否能够正常结束
开始验证-开始验证-开始验证-结束验证-结束验证-结束验证，是否能够正常结束
开始验证-关闭浏览器，下次能否正常使用
开始验证-关机，下次能否正常使用
开始验证-不关闭，过段时间后是否能够正常使用


4. 并发测试：
模拟多并发场景，是否出现串音或其他情况
5. 性能测试：
全链路性能测试，
3. 稳定性测试：
持续验证，不停止，持续进行24小时
6. 异常测试：


1. 终端数据采集工具
2. 智能训练为什么选择xgboost和逻辑回归


1. 通过121跳转到其他服务器，用户名密码？
2. 如何连接服务器数据库？172.16.0.143的localhost:9000/mem:echo；172.16.0.212的localhost/mem:echo；日志节点jdbc:h2:tcp://localhost/localdb/pstnLog

1. 
自己在多家单位工作过，有国企也有民企，在每家单位给领导和同事留下的印象都很好，期间分别承担过一些攻坚克难的任务，都取得了不错的成绩；
在这个过程中发现自己可以做还是更适合做一些科研类、专业性强的工作，

而我认为电信研究院做的事情也都比较专业，跟我的意愿
厚积薄发
在一个领域深耕
长跑型选手

我是董彩超，6月份入职，现在是业务与应用创新研究所的一名员工，研究生毕业后一直从事软件开发相关工作，到现在也有6个年头了，先后在传统企业和互联网类型企业工作过，体验了不同的工作模式（一个是按部就班，一个是）。虽然在这不同的模式下，都能够通过自己的努力取得不错的成绩，但过程中越来越发现什么才是适合自己的。就个人而言，在一个更稳定、更平和的工作环境中能够最大化的发挥自身的优势（踏实肯干、耐力型选手、不求一鸣惊人，但求日久见人心），实现可持续稳定发展。这也是我选择电信研究院的原因。适合自己的才是最好的。
1. 适合自己，就个人而言，在一个更稳定、更平和的工作环境中能够最大化的发挥自身的优势（踏实肯干、耐力型选手、不求一鸣惊人，但求日久见人心）。这也是我选择电信研究院的原因
2. 电信是很好的企业，很好的平台
3. 能够很好平衡家庭生活和工作

我是董彩超，6月份入职，现在是业务与应用创新研究所的一名员工，研究生毕业后一直从事软件开发相关工作，到现在也有6个年头了
我心目中的研究院是：
在这里员工能够不断成长，成长的同时再给研究院输送养分创造价值，相当于一个哺育和反哺的过程，逐渐形成互相促进互相成就的"良性循环"
如果要用几个词描述理想中的研究院的话，我会选择：自由、开放、创新、安静、家文化
自由：不拘泥于形式，给员工不断成长充分发挥的空间（只要能把工作做好，不会限定特定的方式方法，当然是在合理合法的范围内）
开放：保持业界新技术、新科技的敏感度，还可以将一些新的理念、产品或者技术进行输出（新技术及时培训，参与业内开放组织）
创新：鼓励创新，营造良好创新的氛围
安静：每个人都很踏实、不浮躁，能够静下心来做事情
家文化：给员工创造归属感，让员工感受到被需要，被尊重，被爱护

院里有不同的研究方向，咱们有没有提供相互深度交流的机会，类似轮岗或者其他形式？


手机音频质量检测市场占有率较高
汽车领域

人头，模拟真人发声、听声
调整夹机角度，模拟真人使用手机
信号分析
背景噪声，控制音箱发声
acqua，一套软件系统, 语音和音频质量检测系统
背景噪声模拟系统，噪声有统一标准

音频质量检测，没有统一标准

抗背景噪声，
3PASSlab  3PASSflex
语音识别、音质、通信，不同测试功能提供不同方案
消声室国际标准，对方可提供数据参考
3PASS reverb软件模拟消声室的混响，与3PASSlab一起使用
office场景、汽车场景、道路噪声、火车噪声、十字路口
3PASSlab可自己录制噪声场景
3PASSflex主要应用于汽车场景

连接: usb、voIp、蓝牙

smart home hands---HQS；评估多人说话的场景？两人场景；中间转盘模拟声音移动
double talk performance：
音频质量测试，HQS audio：没有统一标准，对扬声器质量测试，单体、外壳

基础测试
frequency response
signal to noise ratio - 信噪比
sound pressure level EN 60268-5, EN 60268-21
TOTAL harmonic distorion  THD
TOTAL harmonic distorion & noise THD+N
tow-tone intermodulation distorion   IMD
distorion rub & BUZZ
relative approach 3D - impulsive distortion
transfer function & impulse response
directivity

感知测试
sound quality
distorions
auditory spaciousness - spatial reproduction quality
overall qulity

语音识别测试 vocas - voice control and analysis system
实际环境下测试智能家居
包含声学配置
模拟背景噪声
模拟各种说话人位置

语音材料自动校准采集
完整声学配置     模拟伦巴效应
完全的测试自动化
语音序列和对话灵活组织
结果统计分析


操作终端、操作场景、网络测试


应用编码-监控指标类型编码-监控指标号码
appName_monitorType_monitorName
日志格式统一以’[’开头
如果该日志需要作为监控项处理，请输入特定字符串”[!|MONITOR!|_${appName}_${monitorName}]”
${appName}_${monitorName}应与监控指标项metric一一对应
异常捕获，包含ERROR关键字、类似sessionid等唯一性信息
请求耗时
请求失败
特定业务含义监控项相关日志输出，例如队列数量

耗时：重要处理耗时
失败：交易失败、处理失败
请求入口和出口、请求处理时间
外部接口调用参数输出、返回结果输出、耗时输出
重要方法入口、业务流程前后以及处理结果，可做debug
重要变量状态变化
特殊操作，例如重连等
when?who where?how what
LOG.debug("Saveorderwithorderno：[{}], andorderamount：[{}]");   使用参数化形式`{}`占位，`[]` 进行参数隔离


我已经签字同意过去5G研发中心了。虽然加入智能语音项目组时间不长，但是在这里我真心感受到了家的温暖，非常感谢各位老师的指导和帮助，现在要拆分组合5G研发中心，不得不离开咱们团队，内心有诸多不舍，也很不舍得离开团队离开810；时间不长，也没有做出什么亮点的工作，希望


阮总，不好意思打扰一下，ceph本身集成了RGW网关支持对象存储，提供rest接口，目前支持S3 API和SWIFT API两种方式，现阶段了解到的情况是直接使用http rest接口相对复杂（构建身份校验、上传或下载对象实体关系尚不明确等），对于工作计划中"对象存储的Restful接口发布"，我想初步先通过S3 SDK方式实现对象数据的上传、下载等操作，提供SDK操作工具类和相关数据下载url模式（只有对象权限设置为公共可读，匿名用户才可下载），后面继续研究ceph部署、使用、S3 API调用、SWIFT API调用等方面的问题和优化，逐渐再确定是否有必要以及如何提供纯http形式的接口，阮总你看这样可否？
另外想从整体角度了解ceph存储在项目流程中的使用过程，这样在调研过程中也会有所思考和侧重，等您出差回来后有时间的话下跟您请教请教；

根据之前整理共计27个异常码，已经实现其中23项，剩余4项尚未实现：其中10101和10201两种异常涉及前端客户端连接，建议由前端实现（10101-录音失败：如麦克风故障、麦克风未开、或声卡未开，10201-客户端连接声纹服务端失败）；由于鉴别会话时长方案尚未确定，20202异常尚未实现（20202-会话长时间未结束）；由于现阶段数据库量级较低，可待系统重构时再关注20212异常项（20212-声纹服务端访问数据库异常）




“不忘初心就是初心不变，牢记使命就要勇担使命。”
革命一块砖,哪里需要往哪搬
要坚守初心、滋养初心、践行初心，强化使命担当、提升本领能力，


我们出发,满怀理想。但是渐渐地,我们的理想被名利取代,保持初心,是记得我们当初为什么出发。有时候你会迷茫,所谓迷茫,不过是给自己找的一个不愿努力的借口,有时候你会彷徨,所谓彷徨,不过是给自己找的另一个不愿努力的借口。每个人都有自己的初心,关键是你为了坚守它做了哪些努力,也许真正打败你的不是残酷的现实,而是你那颗不愿努力,不愿改变现状的心。不忘初心就是初心不变，是一句口号，更是一份承诺和责任担当。唤起我们最美的初心，然后坚守初心、滋养初心、践行初心，强化使命担当、提升本领能力；调整我们的心态，认清自己的位置，体现“革命一块砖,哪里需要往哪搬”的奉献精神，为电信研究院以及中国电信的科技创新和发展奉献自己的一份力量；


"acl", "torrent","logging", "location", "policy", "requestPayment", "versioning","versions", "versionId", "notification", "uploadId", "uploads","partNumber","website","delete", "lifecycle", "tagging", "cors","restore"。
acl, lifecycle,location, logging, notification, partNumber, policy,requestPayment,torrent, uploadId, uploads, versionId, versioning,versions 和 website


ceph osd pool delete cephfs_data cephfs_data -–yes-i-really-really-mean-it
ceph osd pool delete cephfs_metadata cephfs_metadata -–yes-i-really-really-mean-it
ceph osd pool delete mytest mytest --yes-i-really-really-mean-it
ceph osd pool delete rdb_test rdb_test --yes-i-really-really-mean-it
ceph osd pool delete .rgw.root .rgw.root --yes-i-really-really-mean-it
ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it
ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it
ceph osd pool rm default.rgw.log default.rgw.log --yes-i-really-really-mean-it
ceph osd pool rm default.rgw.buckets.index default.rgw.buckets.index --yes-i-really-really-mean-it
ceph osd pool rm default.rgw.buckets.data default.rgw.buckets.data --yes-i-really-really-mean-it


1. httpconnection可用
2. sdk可用
3. httpconnection调用sdk的签名，不可用

第一步：确保初始状态（只有date、method、resourcepath）都能通过（httpconnection、restutils调用main方法、httpconnection调用sdk签名、）
第二步：增加其他参数（acl等），再次测试

<CreateBucketConfiguration xmlns="http://s3.amazonaws.com/doc/2006-03-01/"><LocationConstraint>default</LocationConstraint></CreateBucketConfiguration>


pvcreate /dev/loop0 -u D5a5zj-FW82-apOj-3I28-6HhA-sXDC-0hhyV5 --restorefile /etc/lvm/backup/ceph-volumes
ceph --admin-daemon /var/run/ceph/ceph-client.rgw.mecpass6.910758.94598274736680.asok perf dump
http://mecpass1:8080/#/dashboard

radosgw-admin user create --uid=admin_2 --display-name=admin_2 --system

  0        0         0       0 524353536 1583     1583 active+clean 2019-07-26 10:05:17.715749 14'3583  14:3670 [1]          1    [1]              1        0'0 2019-07-26 10:01:20.337218             0'0 2019-07-26 10:01:20.337218
ceph-objectstore-tool --op fuse --data-path /var/lib/ceph/osd/ceph-1 --mountpoint /osdmount/
[root@lab101 ~]# ll /osdmount/1.7_head/all/#1:fc00bae4:::rbd_data.10166b8b4567.00000000000001fc:head#/data
-rwx------ 1 root root 4194304 Jan  1  1970 /osdmount/1.7_head/all/#1:fc00bae4:::rbd_data.10166b8b4567.00000000000001fc:head#/data
[root@lab101 ~]# md5sum /osdmount/1.7_head/all/#1:fc00bae4:::rbd_data.10166b8b4567.00000000000001fc:head#/data
7def453c4a818e6cd542bfba4dea9943  /osdmount/1.7_head/all/#1:fc00bae4:::rbd_data.10166b8b4567.00000000000001fc:head#/data
[root@lab101 ~]# cp /osdmount/1.7_head/all/#1:fc00bae4:::rbd_data.10166b8b4567.00000000000001fc:head#/data /tmp/rbd_data.10166b8b4567.00000000000001fc-inbluestore
[root@lab101 ceph]# rados -p rbd ls|grep 00000000000001fc
rbd_data.10166b8b4567.00000000000001fc
[root@lab101 ceph]# rados -p rbd get rbd_data.10166b8b4567.00000000000001fc /tmp/rbd_data.10166b8b4567.00000000000001fc-radosget

.nELtbkHY3H-qW0pHkps5sUX5kf4iCIt_

刚刚学习Ceph，部署的时候遇到一个问题，还望各位帮忙看看，谢谢；
问题描述：使用v14.2.2 Nautilus版本，部署OSD时指定的data目录通过LVM方式（lvcreate创建），几天后会出现OSD掉线，同时数据目录（/var/lib/ceph/osd/ceph-0）内容被清空、ceph目录挂载消失（通过df -hl和lsblk查看），想问一下怎么恢复？
lvcreate -L 9G -n dong dongcaichao
ceph-deploy osd create --data ceph-volumes/ceph1 mecpass6
mount /dev/ceph-volumes /var/lib/ceph/osd/ceph-7



[HTTP/1.1 200 OK]
Cache-Control: [no-cache]
ETag: ["f1c9645dbc14efddc7d8a322685f26eb"]
Connection: [Keep-Alive]
x-amz-request-id: [tx000000000000000000003-005db17c56-64e8-default]
Last-Modified: [Thu, 10 Oct 2019 01:02:46 GMT]
Content-Length: [10485760]
Date: [Thu, 24 Oct 2019 10:26:30 GMT]
x-rgw-object-type: [Normal]
Content-Type: [binary/octet-stream]

[HTTP/1.1 200 OK]
Cache-Control: [no-cache]
ETag: ["f1c9645dbc14efddc7d8a322685f26eb"]
Connection: [Keep-Alive]
x-amz-request-id: [tx000000000000000000006-005db17e9f-64e8-default]
Last-Modified: [Thu, 10 Oct 2019 01:02:46 GMT]
Content-Length: [10485760]
Date: [Thu, 24 Oct 2019 10:36:15 GMT]
x-rgw-object-type: [Normal]
Content-Type: [binary/octet-stream]


<LifecycleConfiguration><Rule><ID>firstrule</ID><Prefix>play</Prefix><Status>Enabled</Status><Expiration><Days>3</Days></Expiration></Rule><Rule><ID>secondrule</ID><Prefix>output</Prefix><Status>Enabled</Status><Expiration><Days>4</Days></Expiration></Rule></LifecycleConfiguration>

<LifecycleConfiguration>
<Rule>
<ID>UniqueIdentifier</ID>
<Prefix>Prefix</Prefix>
<Status>LifecycleStatus</Status>
<Expiration>
<Days>NumberOfDays</Days>
</Expiration>
</Rule>
</LifecycleConfiguration>

<LifecycleConfiguration><Rule><ID>example-id</ID><Filter><Prefix>logs/</Prefix></Filter><Status>Enabled</Status><Transition><Days>30</Days><StorageClass>STANDARD_IA</StorageClass></Transition><Transition><Days>90</Days><StorageClass>GLACIER</StorageClass></Transition><Expiration><Days>365</Days></Expiration></Rule></LifecycleConfiguration>

<LifecycleConfiguration><Rule><ID>NewRule</ID><Prefix></Prefix><Status>Enabled</Status><Expiration><Days>3</Days></Expiration></Rule></LifecycleConfiguration>
<LifecycleConfiguration><Rule><ID>NewRule</ID><Prefix></Prefix><Status>Enabled</Status><Expiration><Days>3</Days></Expiration></Rule><Rule><ID>NewRule</ID><Status>Enabled</Status><Filter><And><Prefix>YearlyDocuments/</Prefix><Tag><Key>expire_after</Key><Value>ten_years</Value></Tag></And></Filter><Expiration><Days>3650</Days></Expiration></Rule>

<LifecycleConfiguration><Rule><ID>NewRule</ID><Status>Enabled</Status><Filter><Prefix>play</Prefix></Filter><Expiration><Days>3</Days></Expiration></Rule></LifecycleConfiguration>

10月 29 14:13:41 mecpass1 alertmanager[2317040]: level=error ts=2019-10-29T06:13:41.339Z caller=coordinator.go:124 component=configuration msg="Loading configuration fi

入党时间和政治面貌都不能改
信息系统项目管理师个别信息不准确
罗宇楹 <luoyy6@chinatelecom.cn>

人员基本信息-修改照片
家庭信息-添加父亲、母亲、弟弟，修改妻子信息（职务、地址、身份证号）
学历信息-"天津大学"部分增加院系、设置第一学历
职业资格-添加"信息系统项目管理师"（注：信息系统项目管理师原件在周继佑老师保管的档案袋中，故部分信息未填写）

ceph dashboard set-alertmanager-api-host 'http://172.16.245.10:9093'



groups:
- name: 内存报警规则
  rules:
  - alert: NodeMemoryUsage
    expr: (node_memory_MemTotal_bytes - (node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes )) / node_memory_MemTotal_bytes * 100 > 80
    for: 1m
    labels:
      user: prometheus
    annotations:
      summary: "{{$labels.instance}}: High Memory usage detected"
      description: "{{$labels.instance}}: Memory usage is above 80% (current value is:{{ $value }})"

groups:
- name: node存活报警规则
  rules:
  - alert: InstanceDown
    expr: up == 0
    for: 1m
    labels:
      user: prometheus
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minutes."

https://prometheus.io/download/
https://mail.163.com/js6/main.jsp?sid=CAWtMqGUTotvZamLOZUUlXCDgebsNuLU&df=unknow#module=welcome.WelcomeModule%7C%7B%7D

ceph_cluster_total_used_raw_bytes 6,210,781,184.0
ceph_cluster_total_used_bytes 842,072,064.0
ceph_cluster_total_bytes 48,318,382,080.0

rados -p default.rgw.buckets.data load-gen --read-percent 0 --min-object-size 1073741824 --max-object-size 1073741824 --max-ops 1 --min-op-len 4194304 --max-op-len 4194304 --target-throughput 1073741824 --max_backlog 1073741824
rados -p default.rgw.buckets.data load-gen --num-objects 128 --min-object-size 1073741824 --max-object-size 1073741824 --run-length 20 --read-percent 0 --min-op-len 4194304 --max-op-len 4194304 --target-throughput 104857600 --max_backlog 104857600 --max-ops 64
ceph osd pool set default.rgw.buckets.data  pg_num 256
ceph osd pool set default.rgw.buckets.index  pg_num 256


<LifecycleConfiguration><Rule><ID>111</ID><Prefix>documents</Prefix><Status>Enabled</Status><Expiration><Days>30</Days></Expiration></Rule><Rule><ID>222</ID><Prefix>documents/2011</Prefix><Status>Enabled</Status><Expiration><Days>365</Days></Expiration></Rule></LifecycleConfiguration>


radosgw-admin --tenant testx --uid tester --display-name "Test User" --access_key TESTER --secret test123 user create

{    "user_id": "testx$tester",    "display_name": "Test User",    "email": "",    "suspended": 0,    "max_buckets": 1000,    "subusers": [],    "keys": [        {            "user": "testx$tester",            "access_key": "TESTER",            "secret_key": "test123"        }    ],    "swift_keys": [],    "caps": [],    "op_mask": "read, write, delete",    "default_placement": "",    "default_storage_class": "",    "placement_tags": [],    "bucket_quota": {        "enabled": false,        "check_on_raw": false,        "max_size": -1,        "max_size_kb": 0,        "max_objects": -1    },    "user_quota": {        "enabled": false,        "check_on_raw": false,        "max_size": -1,        "max_size_kb": 0,        "max_objects": -1    },    "temp_url_keys": [],    "type": "rgw",    "mfa_ids": []}


radosgw-admin --tenant testx --uid tester5 --display-name "Test User5" --access_key TESTER5 --secret test5 user create
radosgw-admin user rm --tenant testx --uid tester5


// Direct stderr output of command
    InputStream err = ((ChannelExec)c).getErrStream();
    InputStreamReader errStrRdr = new InputStreamReader(err, "UTF8");
    Reader errStrBufRdr = new BufferedReader(errStrRdr);

    // Direct stdout output of command
    InputStream out = c.getInputStream();
    InputStreamReader outStrRdr = new InputStreamReader(out, "UTF8");
    Reader outStrBufRdr = new BufferedReader(outStrRdr);

    c.connect();
    while(true)
    {
        if(c.isClosed()) {
            results.exitCode = c.getExitStatus();
            break;
        }
        try{
            Thread.sleep(1000);
        } catch(InterruptedException ie) { }
    }
    c.disconnect();

    int ch;
    StringBuffer stdout = new StringBuffer();
    while ((ch = outStrBufRdr.read()) > -1) {
        stdout.append((char)ch);
    }
    results.stdout = stdout.toString();
    StringBuffer stderr = new StringBuffer();
    while ((ch = errStrBufRdr.read()) > -1) {
        stderr.append((char)ch);
    }
    results.stderr = stderr.toString();
	
{"uid":"dongcc","display-name":"dong cc","tenant":"tenant1"}
/admin/user?format=json&uid=dongcc&display-name=dong-cc&tenant=tenant1

[{"user":"tenant2$dongcc","access_key":"8L3K8UETUB7YCJKS2RCX","secret_key":"DBBoMESjWNVcey9q7UBmtEGreTjd82mvye9l8gOb"},{"user":"tenant2$dongcc","access_key":"TIAFP4GA8WTLZIM0F26N","secret_key":"6saHXG6CKlT1fyD0LZ0gBlfc8QHvb3lkIj1uzZYe"}]
{"tenant":"tenant2","user_id":"dongcc","display_name":"dong-cc","email":"","suspended":0,"max_buckets":1000,"subusers":[],"keys":[{"user":"tenant2$dongcc","access_key":"8L3K8UETUB7YCJKS2RCX","secret_key":"DBBoMESjWNVcey9q7UBmtEGreTjd82mvye9l8gOb"},{"user":"tenant2$dongcc","access_key":"CCVC3SUA3USWE9VQF4ZZ","secret_key":"hISBEHg3d1lgYUM3KmUuYas4tm0fMTjDKqzTDpcK"},{"user":"tenant2$dongcc","access_key":"VZZX5RAFFW4ZGD0GEI9D","secret_key":"bYnhu1MmnbSJkopGLhD9TN0EXwesqjZKkHE5z09K"}],"swift_keys":[],"caps":[],"op_mask":"read, write, delete","system":"false","default_placement":"","default_storage_class":"","placement_tags":[],"bucket_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"user_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"temp_url_keys":[],"type":"rgw","mfa_ids":[]}
{"tenant":"tenant2","user_id":"dongcc","display_name":"dong-cc","email":"","suspended":0,"max_buckets":1000,"subusers":[],"keys":[{"user":"tenant2$dongcc","access_key":"8L3K8UETUB7YCJKS2RCX","secret_key":"DBBoMESjWNVcey9q7UBmtEGreTjd82mvye9l8gOb"},{"user":"tenant2$dongcc","access_key":"CCVC3SUA3USWE9VQF4ZZ","secret_key":"hISBEHg3d1lgYUM3KmUuYas4tm0fMTjDKqzTDpcK"},{"user":"tenant2$dongcc","access_key":"HMAM6WBOC1CI9BLR3I4W","secret_key":"X1taaK7NESdvRLlBV5IXyYkuqqAioUFLJa1PCIZv"},{"user":"tenant2$dongcc","access_key":"VZZX5RAFFW4ZGD0GEI9D","secret_key":"bYnhu1MmnbSJkopGLhD9TN0EXwesqjZKkHE5z09K"}],"swift_keys":[],"caps":[],"op_mask":"read, write, delete","system":"false","default_placement":"","default_storage_class":"","placement_tags":[],"bucket_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"user_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"temp_url_keys":[],"type":"rgw","mfa_ids":[]}

{"tenant":"tenant2","user_id":"dongcc","display_name":"dongCAICHAO","email":"","suspended":0,"max_buckets":1000,"subusers":[],"keys":[{"user":"tenant2$dongcc","access_key":"8L3K8UETUB7YCJKS2RCX","secret_key":"DBBoMESjWNVcey9q7UBmtEGreTjd82mvye9l8gOb"},{"user":"tenant2$dongcc","access_key":"CCVC3SUA3USWE9VQF4ZZ","secret_key":"hISBEHg3d1lgYUM3KmUuYas4tm0fMTjDKqzTDpcK"},{"user":"tenant2$dongcc","access_key":"EEZNLSEA6CW03DRJTXLZ","secret_key":"LAZSUm85jMHOjBywKGDY7d6k8aajIdHNpvtARsBr"},{"user":"tenant2$dongcc","access_key":"HMAM6WBOC1CI9BLR3I4W","secret_key":"X1taaK7NESdvRLlBV5IXyYkuqqAioUFLJa1PCIZv"},{"user":"tenant2$dongcc","access_key":"VZZX5RAFFW4ZGD0GEI9D","secret_key":"bYnhu1MmnbSJkopGLhD9TN0EXwesqjZKkHE5z09K"}],"swift_keys":[],"caps":[],"op_mask":"read, write, delete","system":"false","default_placement":"","default_storage_class":"","placement_tags":[],"bucket_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"user_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"temp_url_keys":[],"type":"rgw","mfa_ids":[]}

[{"user":"tenant2$dongcc","access_key":"8L3K8UETUB7YCJKS2RCX","secret_key":"DBBoMESjWNVcey9q7UBmtEGreTjd82mvye9l8gOb"},{"user":"tenant2$dongcc","access_key":"CCVC3SUA3USWE9VQF4ZZ","secret_key":"hISBEHg3d1lgYUM3KmUuYas4tm0fMTjDKqzTDpcK"},{"user":"tenant2$dongcc","access_key":"EEZNLSEA6CW03DRJTXLZ","secret_key":"LAZSUm85jMHOjBywKGDY7d6k8aajIdHNpvtARsBr"},{"user":"tenant2$dongcc","access_key":"HMAM6WBOC1CI9BLR3I4W","secret_key":"X1taaK7NESdvRLlBV5IXyYkuqqAioUFLJa1PCIZv"},{"user":"tenant2$dongcc","access_key":"R0K8CCFACB5EQF49JFFK","secret_key":"n2WDsrkPfkXl0fzNY7oquVN0pHVN00qKn5in9NRy"},{"user":"tenant2$dongcc","access_key":"VZZX5RAFFW4ZGD0GEI9D","secret_key":"bYnhu1MmnbSJkopGLhD9TN0EXwesqjZKkHE5z09K"}]

{"tenant":"tenant2","user_id":"dongcc","display_name":"dongCAICHAO","email":"","suspended":0,"max_buckets":1000,"subusers":[],"keys":[{"user":"tenant2$dongcc","access_key":"8L3K8UETUB7YCJKS2RCX","secret_key":"DBBoMESjWNVcey9q7UBmtEGreTjd82mvye9l8gOb"},{"user":"tenant2$dongcc","access_key":"CCVC3SUA3USWE9VQF4ZZ","secret_key":"hISBEHg3d1lgYUM3KmUuYas4tm0fMTjDKqzTDpcK"},{"user":"tenant2$dongcc","access_key":"EEZNLSEA6CW03DRJTXLZ","secret_key":"LAZSUm85jMHOjBywKGDY7d6k8aajIdHNpvtARsBr"},{"user":"tenant2$dongcc","access_key":"HMAM6WBOC1CI9BLR3I4W","secret_key":"X1taaK7NESdvRLlBV5IXyYkuqqAioUFLJa1PCIZv"},{"user":"tenant2$dongcc","access_key":"VZZX5RAFFW4ZGD0GEI9D","secret_key":"bYnhu1MmnbSJkopGLhD9TN0EXwesqjZKkHE5z09K"}],"swift_keys":[],"caps":[],"op_mask":"read, write, delete","system":"false","default_placement":"","default_storage_class":"","placement_tags":[],"bucket_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"user_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"temp_url_keys":[],"type":"rgw","mfa_ids":[]}

curl http://127.0.0.1:18088/driver/index.html
curl http://172.16.245.13:18088/driver/index.html
curl http://172.16.245.14:18088/driver/index.html

mss物流申请  规格  缘由


[mon.a]
    host = mecpass1
    addr = 172.16.245.10:6789
[mon.b]
    host = mecpass3
    addr = 172.16.245.12:6789
[mon.c]
    host = mecpass5
    addr = 172.16.245.14:6789
	
2996Dong423
258156334@qq.com
各位好，最近搭建了一个比较小规模的Ceph集群，使用了一段时间后发现数据不均匀，刚刚接触ceph集群，有几个问题请教一下各位，谢谢；
问题1：通过ceph osd df命令查看几个OSD节点磁盘使用比例相差较大，几次调整osd的reweight未启作用，请问有其他方法吗？
问题2：通过ceph df命令查看default.rgw.buckets.data这个pool的%used占比是94%，与raw storage的占比相差较大，请问是什么原因呢？
问题3：通过ceph df命令查看default.rgw.buckets.data这个pool的stored和used这两列的解相差一倍，想请问下stored和used两列的统计说明是什么，集群中设置的副本数是2，此处stored


osdmaptool osd.map --upmap out.txt --upmap-pool default.rgw.buckets.data
/usr/bin/ceph-osd -f --cluster ceph --id 6 --setuser ceph --setgroup ceph --osd-data /home/ceph-6

 9   noin
6 norecover nobackfill
ceph tell osd.* injectargs '--mon-osd-nearfull-ratio 0.995'
ceph tell osd.* injectargs '--mon_osd_nearfull_ratio 0.995'

ceph tell osd.10 config set mon_osd_nearfull_ratio 0.99

ceph daemon osd.0 config set debug_osd 20/5
ceph daemon osd.2 config set debug_osd 20/5
ceph osd unset norecover
ceph osd unset nobackfill


mycontainers17  3 myobjects31/39/49
mycontainers18  3 myobjects13/48/50
mycontainers19  3 myobjects22/24/29
mycontainers2   1 myobjects17
mycontainers20  2 myobjects16/4
mycontainers21  1 myobjects11
mycontainers22  4 myobjects15/30/42/47
mycontainers23  1 myobjects3
mycontainers24  3个
mycontainers25  4个
mycontainers26  2个
mycontainers27  3个
mycontainers28  6个
mycontainers29  2个
mycontainers30  1个
mycontainers31  3
mycontainers32  2


dd if=/dev/zero of=/home/ceph/ceph-volumes-2g.img bs=1M count=2048 oflag=direct

岗位1：Ceph存储开发运维工程师
岗位职责：
1. 分布式存储(Ceph)设计与开发，分布式存储性能分析与优化；
2. 分布式存储(Ceph)系统运维支持，及时发现系统隐患、瓶颈，并解决问题；
任职资格：
1. 学历全日制本科（211或985）以上；
2. 熟悉Linux系统编程，C/C++/java语言，掌握一门脚本编程语言（bash、python等），熟悉常用的数据结构和算法；
3. 熟悉Ceph，有线上部署、日常运维、扩缩容、性能分析、故障定位处理能力；
4. 熟练使用Ansible、Salt等自动化运维工具;
5. 深入理解分布式算法原理（PAXOS）;
6. 有钻研精神，态度积极，自我驱动，能看懂英文资料；

你能得到什么：
1. 工作：优质的办公环境下，丰富的实际项目等着你;
2. 通勤：班车遍布北京，涉及各大高校，方便又快捷，不用为上下班的通勤而烦恼;
3. 生活：自助餐厅美食任你吃，健身房设备齐全环境好，运动场散步打球都可以，助你劳逸结合身心全面发展;
你来做什么: 
1. 分布式存储(Ceph)设计与开发，分布式存储性能分析与优化;
2. 分布式存储(Ceph)系统运维支持，及时发现系统隐患、瓶颈，并解决问题;
你需要具备什么: 
1. 学历全日制本科（211或985）以上;
2. 熟悉Linux系统编程，C/C++/java语言，掌握一门脚本编程语言（bash、python等），熟悉常用的数据结构和算法;
3. 熟悉Ceph，有线上部署、日常运维、扩缩容、性能分析、故障定位处理能力;
4. 熟练使用Ansible、Salt等自动化运维工具;
5. 深入理解分布式算法原理（PAXOS）;
6. 有钻研精神，态度积极，自我驱动，能看懂英文资料;

岗位2：Java开发工程师
2. 根据业务需求文档和概要设计文档完成详细设计、代码编写、调试和单元测试；
3 .主导技术难题攻关，持续提升核心能力的高性能、高可用，保证系统的安全、稳定。
系统性的设计技术方案并落地实施，确保项目的进度和质量

1. JAVA基础扎实。精通多线程编程，熟悉分布式,缓存,消息队列等机制；熟悉JVM，包括内存模型、类加载机制以及性能优化；

ceph daemon rgw.mecpass4 config set debug_rgw 20/5


刚刚看了一下，国家信息安全漏洞共享平台现在只是收录了这个越权访问和文件上传漏洞，相关细节还没有公开，现在看主要是对访问密钥管理的缺失；Ceph存储这边支持密钥签名认证（S3格式）、SSL访问、服务端数据加密机制；其中签名认证分为V2和V4两个版本（现在demo中使用v2，后续可升级为V4），测试环境中暂未部署SSL（无证书和域名）和服务端加密机制；

rados bench -p default.rgw.buckets.data 10 write --no-cleanup

ceph osd pool create cephfs_data 32 32
ceph osd pool create cephfs_metadata 32 32
ceph fs new cephfs cephfs_metadata cephfs_data 
ceph-fuse /home/cephfsdir
ceph-fuse -m 172.16.245.10,172.16.245.12,172.16.245.14 /home/cephfsdir --keyring /etc/ceph/ceph.client.admin.keyring --name client.admin
mount -t ceph 172.16.245.10:6789,172.16.245.12:6789,172.16.245.14:6789:/ /home/cephfsdir -o name=admin,secretfile=/etc/ceph/admin.secret
mount -t ceph 172.16.245.14:6789:/ /home/cephfsdir -o name=admin,secret=AQAeUIBdBekdCxAA9n1nhoICMdbV1Z1707nlnA==
mount -vvvv -t ceph 172.16.245.12:6789:/ /home/cephfsdir -o name=admin,secret=AQAeUIBdBekdCxAA9n1nhoICMdbV1Z1707nlnA==

ceph osd pool create default.rgw.buckets.data 128 128

ceph osd pool create rbd 16 16


ceph osd crush show-tunables
ceph osd crush tunables hammer
ceph osd crush tunables jewel

rbd create foo --size 3G --image-feature  layering
ceph osd pool set new_test_cache_tiering hit_set_type bloom

k8s是什么，我们自己做了哪些，不能全部用官网架构图
存储，更生动些（关注重点，云边存储协同），明年6月份整装待发是指完成所有？总结一句话；数据安全；完成情况，成果；
支持私有云和公有云部署，其中公有云中更偏向边缘存储以及云边存储协同

ceph dashboard set-rgw-api-host 172.16.245.14
ceph dashboard set-rgw-api-port 7480

Action=CreateTopic&Name=testtopic&push-endpoint=172.16.245.14:7481

福富对接边缘和云公司两个存储，还是由福富发送到我们，我们再同步到云端
问题解答：现在做到什么，以后做到什么程度，如何做到这个程度
新技术，解决什么问题，为什么选择这个？
任务完成情况，总任务占比
万维的量化指标结果（真对场景，应用层面）
完成所有计划目标，同时部分研究成果已经落地应用
内容如何融合到一起
更快更准的将想要对方了解的信息传递到他脑子



中国电信研究院5G研发中心-开发岗招聘 

你能得到什么：
1、工作：优质的办公环境下，丰富的实际项目等着你；
2、通勤：班车遍布北京，涉及各大高校，方便又快捷，不用为上下班的通勤而烦恼；
3、生活：自助餐厅美食任你吃，健身房设备齐全环境好，运动场散步打球都可以，助你劳逸结合身心全面发展；
4、公司有一定的户口指标（只面向20届应届生）。

你来做什么: 
1、根据开发进度和任务分配,参与后端功能开发；
2、负责处理所参与的功能中出现的技术问题；  
3、完成所负责功能的版本归档、变更以及发布工作；
4、处理线上bug处理。 

你需要具备什么: 
1、计算机及相关专业 / 理工科专业 ；
2、熟练掌握Java或C++的编程，掌握底层原理者优先；
3、掌握数据结构、操作系统，有扎实的数据库技术基础；
4、熟悉Linux编程、计算机网络、并发编程；
5、热爱软件开发工作，有很强的求知欲、学习能力和独立思考能力；
6、脚踏实地、积极主动，有良好的团队合作意识 。

有自信的童鞋简历请砸过来~


[client.rgw.mecpass6]
rgw_frontends=civetweb request_timeout_ms=30000 keep_alive_timeout_ms=30000 enable_keep_alive=yes

存储流量模型，自定义还是由调用方提供
实际场景，或解决哪些问题
SSD，网卡，GPU

多个边缘的用户信息在云端可能重复
用户在边缘和中心分别有配额限制
管理控制台

ngx.log(ngx.INFO, "uri is: ", uri)
ngx.log(ngx.INFO, "args[uid] is: ", uid)

完全自研不太现实；
个人接触ceph到现在分为两个阶段，第一个阶段是搭建集群，学习ceph的基本概念，测试对象存储提供的rest接口，对接福富的视频存储；第二个阶段是边缘中心与云端中心数据同步、数据查询方案的构思；之后还有存储对外提供缓存服务、下发到边缘、系统监控等；

local subrequest_uri = "/rgw_proxy" .. ngx.var.request_uri
                local resp = ngx.location.capture(subrequest_uri,{
                method = ngx.HTTP_PUT, args = args,
                always_forward_body = true
                })
				ngx.redirect("http://172.16.245.13:7480"..ngx.var.request_uri);
dasd@3#@!98



        location / {
            add_header Access-Control-Allow-Origin *;

            ## 如果请求方法是GET，则请求智能访问系统，并break
            if ($request_method = "GET") {
                proxy_pass http://rgw_14;
                break;
            }
            ## 如果请求方法是DELETE，则请求智能访问系统，并break
            if ($request_method = "DELETE") {
                proxy_pass http://rgw_14;
                break;
            }
            ## 如果请求方法是HEAD，则请求智能访问系统，并break
            if ($request_method = "HEAD") {
                proxy_pass http://rgw_14;
                break;
            }
            ## 否则，如果请求url包含 /admin/metadata/user，则请求智能访问系统，并break
            if ($request_uri = "/admin/metadata/user") {
                proxy_pass http://rgw_14;
                break;
            }
            ## 否则，如果请求url包含 /admin/user，则请求智能访问系统，并break
            if ($request_uri ~* "/admin/user?.+") {
                proxy_pass http://rgw_14;
                break;
            }
            ## 否则，如果请求url包含至少两个左斜杠 /[0-9a-z_-]+/[0-9a-z\._-]+\?，并且包含?，则请求智能访问系统，并break
            if ($request_uri ~* "/[0-9a-z_-]+/[0-9a-z\._-]+\?") {
                proxy_pass http://rgw_14;
                break;
            }
            ## 否则，如果请求url包含至少两个左斜杠 /[0-9a-z_-]+/[0-9a-z\._-]+，（此时已经不包含?），则请求边缘rgw，并break
            if ($request_uri ~* "/[0-9a-z_-]+/[0-9a-z\._-]+") {
                proxy_pass http://rgw_13;
                break;
            }
            ## 其余情况（请求方法为PUT DELETE POST，并且请求url只有一个左斜杠），则请求智能访问系统
            proxy_pass http://rgw_14;

        }

intel傲腾/内存存储  做边缘存储，可否先做现在的存储同步方案，然后再做调研
存储是否涉及计费（每个能力层面做计费功能）
边缘存储只能保存近几天的内容
阿里的人来了不知道怎么用，感觉不如今天中科院的人
salary

{"tenant":"","user_id":"testuser","display_name":"testuser","email":"","suspended":0,"max_buckets":1000,"subusers":[],"keys":[{"user":"testuser","access_key":"1BC59IC6E9S3E95G89MN","secret_key":"Sqj4sm28S3AWUtiLkbYYMX30B8NSjvs37PiV6JfD"}],"swift_keys":[],"caps":[],"op_mask":"read, write, delete","system":"false","default_placement":"","default_storage_class":"","placement_tags":[],"bucket_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"user_quota":{"enabled":false,"check_on_raw":false,"max_size":-1,"max_size_kb":0,"max_objects":-1},"temp_url_keys":[],"type":"rgw","mfa_ids":[]}

设置前缀，前缀格式我们提要求，让福富满足；
调研分页的情况；
更新前先查看云端是否存在，通过调用getobjectmetadata方法；

0. 项目是一个整体，需要我们相互协作，出现问题也是；
1. nru12目录是借助s3fs调用getbucket方法，那么在实际查看和上传时是直接调用sdk还是说也借用了s3fs或其他工具？getbucket直接指向云端地址；
2. 为什么要分多层目录，如果没用目录，通过对象名称做区分如何？我理解着目录是传统的存储方式，通过对象存储其实不需要目录；


fio -ioengine=libaio -name=test -filename=/dev/sdd -(sync|fsync)=1 -direct=1 -bs=(4k|4M) -iodepth=(1|32|128) -rw=(write|randwrite)
fio -ioengine=libaio -name=test -filename=/dev/sdd -sync=1 -direct=1 -bs=4M -iodepth=1 -rw=write
fio -ioengine=libaio -name=test -filename=/dev/sdd -fsync=1 -direct=1 -bs=4M -iodepth=1 -rw=write
fio -ioengine=libaio -name=test -filename=/dev/sdd -(sync|fsync)=1 -direct=1 -bs=(4k|4M) -iodepth=(1|32|128) -rw=(write|randwrite)
fio -ioengine=libaio -name=test -filename=/dev/sdd -(sync|fsync)=1 -direct=1 -bs=(4k|4M) -iodepth=(1|32|128) -rw=(write|randwrite)
fio -ioengine=libaio -name=test -filename=/dev/sdd -(sync|fsync)=1 -direct=1 -bs=(4k|4M) -iodepth=(1|32|128) -rw=(write|randwrite)


阮总，刚刚皓达和我陪同杨总、冯总与阿里人员交流，有两点先跟您汇报一下哈
1. 我们提供边缘(云)管理平台，由阿里提供垂直应用场景和解决方案，部署或者对接到管理平台，共同合作，相互补充；
2. 涉及到云边协同部分（他们也提到可参考的内容很少），与阿里共同协商技术方案和实现，具体哪些内容需要协同暂未明确，但可相互沟通；
剩下一些细节待年后回来咱们抽时间再一起探讨哈，看看是不是有其他可以合作或者明确的内容；


rados -p default.rgw.buckets.data load-gen --num-objects 50 --min-object-size 4M --max-object-size 4M --max-ops 16 --min-op-len 4M --max-op-len 4M --percent 5  --target-throughput 1073741824 --run-length 60


rados -p default.rgw.buckets.data load-gen --num-objects 50 --min-object-size 4M --max-object-size 4M --max-ops 1 --min-op-len 4M --max-op-len 4M --percent 5 --target-throughput 2000 --run-length 60

--io-size：单位 byte，默认 4096 bytes = 4K
--io-threads：线程数，默认 16
--io-total：总写入字节，单位为字节，默认 1024M
--io-pattern <seq|rand>：写模式，默认为 seq 即顺序写

Echo163!^#
SmartTerminal@2015!
rbd create --size 600G dongcc --image-feature layering

同步sync
fio -ioengine=libaio -sync=1 -direct=1 -invalidate=1 -name=test -bs=4M -iodepth=32 -rw=read -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -sync=1 -direct=1 -invalidate=1 -name=test -bs=4M -iodepth=32 -rw=write -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -sync=1 -direct=1 -invalidate=1 -name=test -bs=4k -iodepth=128 -rw=randread -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -sync=1 -direct=1 -invalidate=1 -name=test -bs=4k -iodepth=128 -rw=randwrite -runtime=60 -filename=/dev/sdd
同步fsync
fio -ioengine=libaio -fsync=1 -direct=1 -invalidate=1 -name=test -bs=4M -iodepth=32 -rw=read -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -fsync=1 -direct=1 -invalidate=1 -name=test -bs=4M -iodepth=32 -rw=write -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -fsync=1 -direct=1 -invalidate=1 -name=test -bs=4k -iodepth=1 -rw=randread -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -fsync=1 -direct=1 -invalidate=1 -name=test -bs=4k -iodepth=1 -rw=randwrite -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -fsync=1 -direct=1 -invalidate=1 -name=test -bs=4k -iodepth=128 -rw=randread -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -fsync=1 -direct=1 -invalidate=1 -name=test -bs=4k -iodepth=128 -rw=randwrite -runtime=60 -filename=/dev/sdd
峰值的读写带宽
fio -ioengine=libaio -direct=1 -invalidate=1 -name=test -bs=4M -iodepth=128 -rw=randread -runtime=60 -filename=/dev/sdd
fio -ioengine=libaio -direct=1 -invalidate=1 -name=test -bs=4M -iodepth=128 -rw=randwrite -runtime=60 -filename=/dev/sdd



    proxy_request_buffering off;
    proxy_buffering on;
    proxy_buffer_size 4k;
    proxy_buffers 32 2M;
    proxy_busy_buffers_size 4M;
    proxy_max_temp_file_size 0;
	
	tcpdump -w dataDst.pcap -i bond0 dst net ip and port port
	
由于现在的同步方案是异步，并且上传效率远低于删除，可能出现一些异常情况：
1. 文件上传过程中（或者上传中断），又产生删除操作，假设同步模块先执行删除后执行了上传，那么该文件就没有实际删除；
2. 多线程消费kafka队列，假设队列中有上传操作和删除操作，也可能出现上述问题；
3. 删除失败（不存在的文件会报404），是否重试；如果重试，假设再次上传了该文件，重试删除时会将该文件删除；
4. 待续

存储计费功能，对象存储是否需要自主管理，云和边如何区分管理？

现在开发了一版边缘侧使用的管理控制台，支持简单的桶操作、文件操作，还有一些功能需要完善；我们初步考虑主要由管理员使用，没有设计登录+权限管理这些，也是由于剩余的工作量还不少（开发+优化+异常情况分析和完善），想一起讨论下有没有必要；


rgw socket path
rgw obj stripe size
ceph daemon /var/run/ceph/ceph-client.rgw.*.asok perf dump
21RGWGetObj_ObjStore_S3
RGWPutObj_ObjStore_S3
rgw_frontends = "civetweb port=7480 num_threads=500 tcp_nodelay=1 listen_backlog=1000 connection_queue=50 enable_keep_alive=yes keep_alive_timeout_ms=60000 "
        sendfile on;
        tcp_nopush on;
        tcp_nodelay on;
		
		
osd_op_num_threads_per_shard_hdd 2
osd_journal_size 10000
bluestore_cache_size_hdd 1073741824‬->3221225472
client_cache_size 16384->1048576


提供存储连接功能的网卡和 HBA 连接至NUMA 节点 0
journal 设置   journal_max_write_bytes  journal_max_write_entries
ssd磁盘，支持index
index shard


sar命令监控网络，由本机lo回路接收cosbench数据并发送到rgw，由rgw发送到osd（跨服务器，通过eno1）；lo回路接收的数据包与lo发送的数据包相同，lo回路发送的数据包低于eno1发送的数据包个数，但是lo回路发送的数据字节数大于eno1发送的数据字节（两者应该相等或相差不多？）；两台服务器之间eno1网卡的发送与接收相差不多（13服务器eno1接收数据包括rgw应该返回数据与14服务器的osd返回数据之和）；写操作时lo回路发送数据包是eno1发送数据包个数的1/4，lo回路发送数据字节是eno1发送数据字节的1.1倍；读操作时eno1与lo发送数据包个数以及字节数相差更大；

219801A18T918AQ0004M

rook部署方式调研  董
ansible部署方式调研  杜
现有方案可能存在的异常情况整理、分析、优化  杜
admin用户使用场景沟通  杜+董
自研分发网关优化  董
操作系统层级优化  杜
使用流程整理  董
系统部署文档  杜+董
ceph支持k8s存储使用场景整理  董
存储空间管理？？？预警管理？？？

测试过程中涉及到的数据量不大

cosbench - nginx(8082) - dispatchingsystem(18080) - 154(3128) - 11:7480
                                                  - 154(3128) - 13:7480

netstat -n | awk '/^tcp/ {++state[$NF]} END {for(key in state) print key,"\t",state[key]}'
ps -aux | grep Dis | awk '{print $2}' | xargs kill
java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000 -jar DispatchingSystem_ceph_client.jar
#export http_proxy="http://124.127.117.154:3128"
#export https_proxy="http://124.127.117.154:3128"
#export no_proxy="127.0.0.1"

２月份主要进行云边协同各系统模块（智能访问系统、数据同步模块）功能开发测试，设计ceph以及云边协同分发网关性能测试方案，在局域网内初步完成分发网关、数据同步模块的性能测试，依托阿里云对象存储服务（OSS）设计云边协同对比测试方案；２月份完成工作共占比65%；3月份工作计划包括：依托阿里云对象存储服务（OSS）设计云边协同对比测试方案；２月份完成工作共占比65%；3月份主要工作包括：依托OSS服务完成云边协同功能测试以及性能对比测试；云边协同各模块进一步优化（功能完善以及性能调优）；现有方案异常情况整理；系统部署流程梳理并编写相关操作文档；


svm多分类  回归（线性回归、逻辑回归）场景
concurrenthashmap 单例模式  jdbc连接过程
三次连接、四次断开、进程和线程
数据中心系统设计，有哪些注意项

阮总您好，关于后续的工作想跟您确认下，我和金财整理了云边协同过程中可能存在的一些异常情况（也可能不全面，后续会继续补充），3月份计划针对这些问题完善功能，然后梳理系统使用流程和部署文档；我们是想如果没有其他紧急的工作我们就按计划开展功能完善和系统部署相关工作，如果有其他紧急的工作我们就调整一下工作内容；另外想问下您关于云边协同这部分内容后续的规划；
YT2042324462419

边缘节点 -- 读写流程、
加速效果（基于上次测试）、
资源（磁盘空间-三副本、ssd、CPU、内存、网络-支持巨帧、交换机-支持巨帧）、
部署模式（ceph原生部署、nginx、mysql、智能访问系统、数据同步模块、桶通知转存模块）
单机房还是多机房？ceph集群宕机？
链路长-时延长、网络抖动容错性差
就近上传链路短-快速响应、网络稳定性强、自动同步

2020-03-18与福富微信会议：
云录像查询不到的问题
福富docker容器化，明天（19号会议沟通问题，确认计划）
重庆电信，在MEC节点，对接边缘存储

与阮总沟通确认福富容器化，现成mec环境部署Ceph，部署机架？
容错性测试案例：关机、断电、拔网线、拔硬盘、读写混合操作、写删混合操作、读删混合操作、稳定性测试、数据丢数测试
阮总，上午陪我老婆去产检，我挂号看了看中医（手脚出汗），体温还是37度左右（最高37.2，两个体温计），又给开了点儿中药，下午4点过去取药，给您报备一下哈；另外在2月中做了一次肺部CT也没问题

单例模式 优势 使用时应注意哪些
决策树、逻辑回归/线性回归、GBDT的应用场景，是分类还是预测，逻辑回归和线性回归的区别
602.2   -   631.7 (8*8)  -  
CREATE USER 'root'@'%' IDENTIFIED BY 'Root!!2020';

INSERT INTO `user` VALUES (3, NULL, 'dongcch', NULL, 'LTAI4FevsK5BxQ9mP2ZTBTfF', 'dvGM0IMliH7HR8oLEKEXtWktfEFnAE', NULL, NULL, '{}', '1');

503.3 - 567.8(8*64*40M)

43190 43181

1.docker服务部署，提供docker镜像和接口文档，测试case（不少于20），门户展示的宣传文档；
2.物联网公司，测试case，基础case+关注的case；结构化视频分析（19年研究，给2个报告，20年是什么结果），如果没有实际成果（最好可展示），可能就是挂单（钱不好拿）
3.4月8号之前完成

物联网公司，涉及开发测试的内容有物联网视图接入能力和视频结构化用于视频高速检索的能力
20年的工作进度，现在什么阶段，可展示的成果？

2020-03-24: 34 pgs not deep-scrubbed in time

线程安全；线程状态，死锁；thread和runnable的区别；threadlocalmap；创建String；jvm有哪些部分；锁机制；concurrenthashmap；大型网络架构模式；防止sql注入；http请求，post/get，幂等；

java -Xms2G -Xmx4G -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:GCTimeRatio=19 -Xnoclassgc -XX:+DisableExplicitGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=5 -XX:-CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=70 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+PrintClassHistogram -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -Xloggc:log/gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./gc.hprof -jar DispatchingSystem_ceph_buffered_4k.jar

53 23 * * * root /usr/lib64/sa/sa2 -A

1.当前存在，且未过期，访问时直接返回；
2.当前不存在，访问时边缘不存在，那么访问云端，此时数据回放到边缘，下次访问时从边缘获取，此时重新计算生命周期；
3.如果当前是生命周期最后一天，访问该对象，直接返回；第二天再次访问该对象时，第一次访问不存在（此时数据回放），第二次访问时存在；
4.由此模拟LRU

数据回放到边缘时，在metadata中新增一个标识，待下次同步时判断该标识

查询集群存储使用情况

mycat  分布式事务  边缘侧数据如何同步到中心云  redis  微服务拆分  分布式存储
不受云端网络带宽忙/闲的限制，容错性相对较强

编写容错性测试案例，完善分发网关长连接问题，ansible安装ssh服务，完善数据同步模块（接近云端回缘的对象数据进行二次同步的重复操作），ceph边缘加速的演示方案设计和开发

http://127.0.0.1:18082/oss/ossdemo.html
http://127.0.0.1:18082/oss/demo

支付消息消费后如果失败、支付消息写队列失败，数据一致性问题  thread、runnable

virtual_server 172.16.245.111 8082 {
    delay_loop 6
    lb_algo rr
    lb_kind NAT
    persistence_timeout 60
    protocol TCP
    real_server 172.16.245.11 8082 {
        weight 1
        TCP_CHECK{
            connect_port 8082
            retry 3
        }
    }
}

logstash作用， kafka partition， redis 分布式锁， hbase key，region，file， storm 分组，spout阻塞， zookeeper节点类型，分布式锁
es之后再持久化，数据保存在哪儿？ES的作用
征信文件爬取
threadlocal使用，如果不在多线程时使用？
扩展字段，怎么分表
数据库

./configure --prefix=/usr/local/nginx  --with-http_ssl_module --with-http_flv_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre
/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf

普通域名+路径与三级域名的方式对比，为什么采用三级域名这种方式？
python版本，对外提供http服务，内存一直增长？
数据库连接池应该设置多大
查看cpu发现iowait很高
Linux进程状态  s d z，如果出现大量D和Z，应该怎么排查和处理

数据库出现问题修复方式（监控、巡检），工具还是手工，什么工具？
遇到过的比较棘手的问题，如何解决
存储，paas平台的设计方案，GO语言内存管理、内存碎片
服务调用方式

kdump 指定dump文件
perf 分析内存

工作日志，每日疫情填报的工作状态


dd if=/dev/zero of=/data_new/ceph3/ceph-volumes-200g.img bs=1M count=204800 oflag=direct
sgdisk -g --clear /data_new/ceph3/ceph-volumes-200g.img
vgcreate ceph-volumes-ceph3 $(losetup --show -f /data_new/ceph3/ceph-volumes-200g.img)
lvcreate -L 199G -n ceph3 ceph-volumes-ceph3
ceph-deploy osd create --data ceph-volumes-ceph3/ceph3 mecpass4
ceph-deploy osd create --data ceph-volumes-ceph3/ceph3 mecpass5
ceph-mgr-dashboard

ceph tell osd.0 injectargs '--osd_failsafe_full_ratio 0.99'
ceph tell osd.* config set osd_max_backfills 10
osd_recovery_max_active
ceph tell osd.* config set osd_recovery_max_active 10

完成ceph ansible自动化部署脚本，测试通过；天翼云对象存储（融合版）适配性改造（尚未提供账号密码，未测试）；优化智能访问系统，解决客户端关闭导致无可用连接的问题；同步模块添加多进程间的分布式锁；优化演示网页的功能；




rook部署方式调研  董
ansible部署方式调研  杜
现有方案可能存在的异常情况整理、分析、优化  杜
admin用户使用场景沟通  杜+董
自研分发网关优化  董
操作系统层级优化  杜
使用流程整理  董
系统部署文档  杜+董
ceph支持k8s存储使用场景整理  董
存储空间管理？？？预警管理？？？




存储能力可用性测试案例设计，可用性测试过程记录，解决测试期间产生的问题
存储云边协同开发相关，云端仍然采用天翼媒体云（资源约束）？系统高可用体系方案设计和部署、应用开发和优化（功能完善+性能提升）、ceph配置优化，操作系统级优化，整理常用的优化方案
预警信息分类，预警方案设计，预警信息开发和测试，注：初步以邮件通知
部署相关，系统使用说明文档，系统部署文档，系统部署脚本
存储能力运维相关，整理常用运维命令手册，调研ceph集群健康状态；注：集群状态恢复过程中实践经验可能不足
ceph底层原理调研（osd、rgw、bluestore），进一步掌握ceph存储
实际线上环境部署和试运行？？？注：不受我们控制
疑问：6月份做成什么样子？？？如何与MEC平台结合？？？ceph部署也要镜像化？？？
极限测试，压力测试方案

三次连接、四次断开
spark开发

网络安全加密，http三次连接，ssl，对称和非对称，ssl中哪些是对称哪些是非对称
数据结构，红黑树
mysql索引，索引类型，in和exist，union和union all，内连接、左连接、右连接
Java，jvm，常用的集合类以及实现的接口，arraylist和linkedlist，concurrenthashmap，锁公平和非公平，锁升级
spring框架搭建
现在能有户口？
聚簇索引和哈希索引的区别

多线程怎么实现，find判断字符串是否包含子串

304124011320
32648709581

arn:aws:sns:default::httpTopic_rgw12_to_11_18081
arn:aws:sns:default::httpTopic_rgw12_to_11_18082
arn:aws:sns:default::httpTopic_rgw12_to_11_18088

{"Records":[{"eventVersion":"2.2","eventSource":"ceph:s3","awsRegion":"","eventTime":"2020-04-26 03:36:46.204812Z","eventName":"s3:ObjectCreated:Put","userIdentity":{"principalId":"another_user"},"requestParameters":{"sourceIPAddress":""},"responseElements":{"x-amz-request-id":"141849e2-6502-4031-843c-623c18b944dd.134574.836","x-amz-id-2":"20dae-default-default"},"s3":{"s3SchemaVersion":"1.0","configurationId":"snsTopicConfig","bucket":{"name":"bbyBucket","ownerIdentity":{"principalId":"another_user"},"arn":"arn:aws:s3:::bbyBucket","id":"141849e2-6502-4031-843c-623c18b944dd.114138.1"},"object":{"key":"110100/1536/11011400031327043708/20200426/110100_1536_11011400031327043708_20200426_113611.mp4","size":42500473,"etag":"fac984e8730f9bd0c6e1ba28cdb87792","versionId":"","sequencer":"CE01A55EF6B0DB0D","metadata":[]}},"eventId":"1587872206.232501.fac984e8730f9bd0c6e1ba28cdb87792"}]}

hadoop mapreduce 过程中是否有排序，哪些过程会排序；如何优化mapreduce过程、实时计算、离线计算
http长连接、分布式锁、redis增量同步和全量同步、数据分布式分表、跨库查询？数据扩展如何做？如果服务器io比较高如何排查

87289908

消毒液、医用棉球、医用外科口罩、体温计、免洗手消毒液、带喷头消毒液、小孩口罩
工银金融租赁有限公司工会委员会    91120116710935177L
酒精消毒液（80）、酒精湿巾（58，未开）
8*3（酒精消毒液） + 6*5（医用棉球） + 30*5（医用外科口罩） + 45*3（大瓶免洗手消毒液） + 16.5*2（小瓶免洗手消毒液） + 8（体温计） + 39（小孩口罩）
8*3（酒精消毒液） + 6*5（医用棉球） + 30*5（医用外科口罩） + 45*2（大瓶免洗手消毒液）

在5G时代充分发挥运营商网络资源优势以及边缘节点优势，经过多轮调研、设计以及论证，我们基于开源软件定义存储针对视频数据100%设计并自研云边协同组件以实现视频数据读写边缘加速，疫情居家办公期间项目组成员依然严格按照现场办公时间点执行，按时高品质完成边缘加速研发任务，在现有环境中读操作效率提升将近7倍，写操作效率提升至少3倍；


[global]
fsid = bbd9db87-4add-4868-8a55-608d8b36d22e
mon_initial_members = mecpass3
mon_host = 172.16.245.12
auth_cluster_required = cephx
auth_service_required = cephx
auth_client_required = cephx

public network = 172.16.245.0/24
osd_pool_default_size = 2
mon_allow_pool_delete = true
mon_data_avail_warn = 15

# debug rgw = 20

rbd_cache = false


[client.rgw.mecpass2]

rgw_frontends = "civetweb port=7480 num_threads=500 tcp_nodelay=1 enable_keep_alive=yes keep_alive_timeout_ms=60000"
rgw thread pool size = 256
rgw cache enabled = false
rgw_override_bucket_index_max_shards = 20
rgw_max_chunk_size = 1048576



X-Cache: [MISS from smart2]
x-oss-request-id: [5EB520DA9849B43131406FE2]
x-oss-server-time: [3]
Server: [openresty/1.15.8.2]
x-oss-object-type: [Normal]
Connection: [keep-alive]
Last-Modified: [Sat, 28 Mar 2020 07:30:07 GMT]
Date: [Fri, 08 May 2020 09:08:42 GMT]
Via: [1.0 smart2 (squid/3.1.23)]
Content-MD5: [GIbmfPh4PonObdxbsJo5RA==]
Accept-Ranges: [bytes]
x-oss-storage-class: [Standard]
Cache-Control: [max-age=259200]
X-Cache-Lookup: [MISS from smart2:3128]
x-oss-hash-crc64ecma: [6048311690242108660]
ETag: ["1886E67CF8783E89CE6DDC5BB09A3944"]
Content-Length: [41943040]
Content-Type: [application/octet-stream]

s3fs nru12 /home/video/nru12/ -o passwd_file=~/.passwd-s3fs -ourl=http://172.16.245.111:8082 -o use_path_request_style  -o max_write=131072
s3fs mycontainers301 /home/video/mycontainers301/ -o passwd_file=~/.passwd-s3fs-oss -ourl=http://172.16.245.111:8082 -o use_path_request_style  -o max_write=131072

/home/video/mycontainers301/110100/512/11011400031327043708/20200509/110100_512_11011400031327043708_20200509_183533.mp4

for i in {0..7}; do ceph tell osd.$i config set osd_max_backfills 20; done;
for i in {47..49}; do ssh mecpass$i date; done;
sudo sync && echo 3 | sudo tee /proc/sys/vm/drop_caches

resize2fs /dev/sdb
同一交换机做两个不通的IP网段；划分两个不同的vlan；


192.168.245.1/24 vlan-3100
192.168.246.1/24 vlan-2500  51+52
192.168.247.1/24 vlan-25    49+50
interface bridge-arregation 1, 包含GE1/0/47 1/0/48,

10000000
10000000

python与后端通信是socket还是http？
jvm组成，为什么线程处理要用栈
hashmap和concurrenthashmap，put数据的过程，入队是队头还是队尾
多线程继承thread和实现runnable有什么区别
quartz如何避免重复执行
neo4j多线程查询
socket通信，长连接短连接？bio和nio
mysql优化是指、底层原理？主键设置和使用
分布式锁mysql、zk、redis
cpu占用100%如何排查
如何查看gc过程
synchronized实现原理
jieba+向量计算是用什么语言，如何封装和调用
springboot配置化的过程，常用的注解，autowired和resource


rgw：接收请求 - 请求结束
智能访问系统：接收请求 - 本地校验 - 方法准备 - httpclient执行 - httpclient返回response - 数据流传递 - 结束请求
以rgw的角度分析：
两次请求之间间隔20ms左右（client直接到rgw时间隔5ms左右），处理请求耗时87ms左右
以智能访问系统的角度分析
两次请求之间间隔2-3ms，从接收请求到httpclient执行需要4-5ms，httpclient执行到返回response耗时13-14ms，数据流传递耗时90-100ms左右
从日志上分析，rgw请求结束14ms左右之后，智能访问系统请求结束
两次请求之间间隔的耗时差异（15ms左右）是由于rgw请求结束14ms左右之后，智能访问系统请求结束；
rgw单次请求耗时差异（10ms左右），与智能访问系统校验以及httpclient执行请求到返回response的耗时有关；


nohup java -Xdebug -Xrunjdwp:transport=dt_socket,suspend=n,server=y,address=0.0.0.0:5555 -jar  DispatchingSystem.jar > dispatchingsystem_1_thread.log 2>&1 &


"CONSUMER" #5974 daemon prio=5 os_prio=0 tid=0x00007f3e1c018000 nid=0x3d2304 in Object.wait() [0x00007f3f19372000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper.doWrite(NioEndpoint.java:1290)
        - locked <0x0000000690660f10> (a java.util.concurrent.Semaphore)
        at org.apache.tomcat.util.net.SocketWrapperBase.doWrite(SocketWrapperBase.java:741)
        at org.apache.tomcat.util.net.SocketWrapperBase.writeBlocking(SocketWrapperBase.java:561)
        at org.apache.tomcat.util.net.SocketWrapperBase.write(SocketWrapperBase.java:505)
        at org.apache.coyote.http11.Http11OutputBuffer$SocketOutputBuffer.doWrite(Http11OutputBuffer.java:538)
        at org.apache.coyote.http11.filters.IdentityOutputFilter.doWrite(IdentityOutputFilter.java:73)
        at org.apache.coyote.http11.Http11OutputBuffer.doWrite(Http11OutputBuffer.java:190)
        at org.apache.coyote.Response.doWrite(Response.java:601)
        at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:339)
        at org.apache.catalina.connector.OutputBuffer.appendByteArray(OutputBuffer.java:746)
        at org.apache.catalina.connector.OutputBuffer.append(OutputBuffer.java:675)
        at org.apache.catalina.connector.OutputBuffer.writeBytes(OutputBuffer.java:386)
        at org.apache.catalina.connector.OutputBuffer.write(OutputBuffer.java:364)
        at org.apache.catalina.connector.CoyoteOutputStream.write(CoyoteOutputStream.java:96)
        at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
        - locked <0x0000000690764b80> (a java.io.BufferedOutputStream)
        at com.ceph.dispatching.service.OutputConsumerRunnableImpl.run(OutputConsumerRunnableImpl.java:41)
        at java.lang.Thread.run(Thread.java:748)

[client.kubernetes]
        key = 
		
cat <<EOF > raw-block-pvc.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: raw-block-pvc
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Block
  resources:
    requests:
      storage: 1Gi
  storageClassName: csi-rbd-sc
EOF

    [
      {
        "clusterID": "82e65362-72f7-4206-b94d-04e2c5e2d70d",
        "monitors": [
          "10.80.0.41:6789"
        ]
      }
    ]

[client.kubernetes]
        key = AQDYO+hevu5JNBAABtDoGxyPvkf1pO4211PvGg==
		
基于万兆网络，在intel服务器（其中两台，每台服务器4个OSD）两副本的情况下测试直连ceph对象存储网关的效果（一台做网关的客户端，一台做服务端），初步结果如图：
基于万兆网络，在intel服务器（其中两台，每台服务器4个OSD）两副本的情况下测试通过自研分发网关连接ceph对象存储网关的效果（一台做网关的客户端，一台做服务端），初步结果如图：


工作团队，工作时长和工作量，一方面是工作量的变化，一方面是期间不可避免的遇到一些问题
问题钻研，当然需要深入的思考，换个角度也许会有不错的收获；
团队协作，加深交流，充分利用我们的资源；再有就是我们尽量不要只陷入自己这一摊，除了埋头苦干，还要抬头看路
站在服务用户的角度，


Action=CreateTopic
&Name=<topic-name>
&push-endpoint=<endpoint>
[&Attributes.entry.1.key=amqp-exchange&Attributes.entry.1.value=<exchange>]
[&Attributes.entry.2.key=amqp-ack-level&Attributes.entry.2.value=none|broker]
[&Attributes.entry.3.key=verify-ssl&Attributes.entry.3.value=true|false]
[&Attributes.entry.4.key=kafka-ack-level&Attributes.entry.4.value=none|broker]
[&Attributes.entry.5.key=use-ssl&Attributes.entry.5.value=true|false]
[&Attributes.entry.6.key=ca-location&Attributes.entry.6.value=<file path>]
[&Attributes.entry.7.key=OpaqueData&Attributes.entry.7.value=<opaque data>]



1. 边缘能力向多云同步（对象存储），现阶段支持ceph、阿里云、天翼云融合版（未测试），那么继续支持腾讯云，百度云？
2. 现阶段更类似单个用户使用边缘加速，是否需要考虑边缘节点多个用户共同使用的情形，如果不限定那么可能存在个别用户占用较多，占用其他用户空间，如何限定单个用户的上限，就算是边缘存储限额，那么上传会失败，如何继续上传？还是说在之前要规划好lifecycle与存储容量的对应；还要支持在现有限额基础上提升额度；
3. 边缘存储计费功能，需要单独计算每个用户的使用量（存储+下行带宽）
4. 可用性监控
5. 断点上传、下载，是否有必要支持
6. 对象存储支持扩容，尤其是到亿级别存储量，现阶段可能暂不用考虑，后续考虑通过自研网关进行扩容，采用https://mp.weixin.qq.com/s?__biz=MzIyNTIyNzE0Ng==&mid=2247486212&idx=1&sn=532cf87b7bea7ab512ee12313281aa56&chksm=e803b3e1df743af78f69f629052a3e2f3133ce3e99bd03a4483bb117b6fa637583b54a5f809a&scene=0&xtrack=1&key=64639d7a7241cf267edf193846e8fc8a11e377a05fdd3f96b9b299f66463685f28d1c22eac06049d4aa0543968df3a4c449c9bf83d79e7f551d331db29acfeb946e7f8f53c889444e1207be79522b1b8&ascene=1&uin=MjI5MDY2OTcwNA%3D%3D&devicetype=Windows+10&version=62070158&lang=zh_CN&exportkey=AVDPAockJ453mlDugqapUwM%3D&pass_ticket=6TJJqUtCwIThyL4mvBYYl70c6lxO6J2KDfuPFvaSYz%2BMpX2T7Ou9t6bMhrqwgkbv
7. 基础存储是包含对象存储+块存储+文件系统？
8. 云边协同是指对象存储，块存储和文件系统不支持准实时同步，考虑迁移方案？时间间隔较长
9. 块存储+文件系统计费，在申请空间时计费？还是按照实际使用空间进行计费；
10. 存储系统运营（运维和实施）由我们支持还是交由其他团队？涉及到的人力资源比较多
11. 关注ceph社区动态
阮总是否有一些规划？

云边协同接口-21cn；将服务部署到南京节点；检索南京资源情况，是否可用；镜像下发，部署模板下发；  郭强
与腾讯云对接，提供接口，由对方调用即可把服务部署到我们的边缘
我们的边缘与我们的云端/对方的云端进行同步

71...........................fortissl
10.9.52.33

'{"scheme":"$scheme","http_host":"$http_host","remote_addr":"$remote_addr","server_addr":"$server_addr","time_local":"[$time_local]","request":"$request","status":$status,"body_bytes_sent":$body_bytes_sent,"http_referer":"$http_referer","http_user_agent":"$http_user_agent","upstream_addr":"$upstream_addr","upsteam_response_time":$upstream_response_time,"request_time":$request_time,"http_x_forwarded_for":"$http_x_forwarded_for","content_length":"$content_length","request_length":$request_length,"request_method":"$request_method","server_protocol":"$server_protocol","request_uri":"$request_uri","x_rgw_request_id":"$upstream_http_x_amz_request_id","access_key":"$authorization"}';

'{"remote_addr":"$remote_addr","remote_port":"$remote_port","remote_user":"$remote_user","time_local":"$time_local","msec":"$msec","request":"$request","status":"$status","body_bytes_sent":"$body_bytes_sent","http_referer":"$http_referer","http_user_agent":"$http_user_agent","http_x_forwarded_for":"$http_x_forwarded_for","request_time":"$request_time","upstream_connect_time":"$upstream_connect_time","upstream_header_time":"$upstream_header_time","upstream_response_time":"$upstream_response_time","http_AUTHORIZATION":"$http_AUTHORIZATION"}'
    log_format  main  '$remote_addr:$remote_port - $remote_user [$time_local] - "$msec" "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"'
                      ' "$request_time" "$upstream_connect_time" "$upstream_header_time" "$upstream_response_time"'
                      '$http_AUTHORIZATION';

route add 14.116.151.138 10.9.52.18 if 71

13EFF704152E2BB74077A696B3C6FA2507E38590
81c6057b-95c0-4668-bf55-ca93f39bdafe

对象存储设置用户quota：https://docs.ceph.com/docs/master/radosgw/admin/#quota-management
例如：radosgw-admin quota set --quota-scope=user --uid=johndoe --max-objects=1024 --max-size=1024G

【姓名】 董彩超
【所在城市】 北京
【就职公司】 中国电信研究院
【职位】 科研人员
【三个希望被记住的标签】 专注、踏实、理工男
【最牛的经历】 通过思考最终解决技术难题
【最希望解决的问题】 跳出技术思维定势

2020-07-09
以往招聘首先是明确招聘需求，然后更多的是关注工作经验、如何尽快招到人，很少有系统、深层次的思考（比如招聘质量的衡量、招聘成功的衡量、工作动机和文化的匹配等），在控制成本的同时提升候选人的覆盖率和命中率并招聘到合适的候选人着实不是一件容易的事情，希望通过本次学习有更全面的思考，期待后续的学习。
有两个问题值得深思：1. 招聘时工作经验是基础，基于此如何在招聘时尽快挖掘到候选人的动机呢？
2. 如何通过一些既定模式或者方法能在大规模招聘时兼顾短周期和高质量呢？

https://bbs.huaweicloud.com/videos/102748
https://bbs.huaweicloud.com/videos/102749
https://bbs.huaweicloud.com/videos/102750

CREATE TABLE `t_app_info_service_template_ref` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `app_info_id` int(255) NOT NULL COMMENT 'app包Id',
  `service_template_id` varchar(255) NOT NULL COMMENT '服务模板名称',
  `project_id` int(11) NOT NULL COMMENT '所属项目Id',
  `org_id` int(11) NOT NULL COMMENT '所属机构Id',
  `department_id` int(11) NOT NULL COMMENT '所属部门Id',
  `creator` varchar(30) DEFAULT NULL COMMENT '创建者',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=10830 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;

2020-07-10
招聘时根据职位分层、根据周期压力分层，项目周期不同阶段的招聘模式需要有所调整：
初期可能需要更快招入有经验的中级人才以及少量高级人才；中期或者攻坚阶段根据实际情况可能只需要高级人才；还有可根据发展战略定期“定量”进行校招以期储备人才；
招聘是一个双向选择过程，期间如果能够换位思考（比如对方最迫切想得到哪些，我们能提供哪些），这样对于提升招聘质量以及成功率应该都有帮助；
2020-07-11
如果能够准确认识员工的工作价值观有助于员工适应企业、员工助力企业、企业挖掘员工潜力等，现在多数应聘者可以归属到85后、90后、00后三个区间，不同区间应聘者的工作价值观以及诉求有较大差异，如何在招聘过程中快速准确识别应聘者的工作价值观值得深思，非常期待后续的课程，希望能够学习到认识工作价值观的一些方法论或者技巧；
2020-07-12
组织生命周期以及挑战和机遇从各位老师这里学到了很多，收获颇丰。
居安思危！更何况现阶段"安"这一部分也逐渐被互联网/设备厂商等企业蚕食！
个人认为3B策略与项目周期分层/招聘人员分层应该是相互关联相辅相成的；
项目周期分层剖析：在企业/项目前期应该更注重Buy；项目中后期应该更注重Build，增强项目和团队的把控能力；根据项目具体情况以及自主可控程度可全程采用Borrow策略；人员总体占比可参考3:5:2；
从老师的3B策略出发，不同的任务需要不同人员：
策略	任务	人员	占比
买（Buy）	项目攻坚，解决技术难题等	细分领域经验丰富人员/领军人	3
建（Build）	后备力量储备，逐渐成长为中坚力量	校招	5
借（Borrow）	解决紧急（不重要）工作，但是借方要有整体把控能力	外包人员/第三方公司	2

2020-07-14
1. 最好的人不一定是最合适的，合适的才是最好的；
2. 精准定位与工作分析对人才招聘策略的有效性很有帮助；
3. 工作分析产出职位说明书，工作分析时由具体岗位实现各流程节点的工作，可以提高效率；
4. 从横向（领导力、全员核心胜任能力、专业序列胜任能力）和纵向（学习阶段、应用阶段、扩展阶段、指导阶段、领导创新阶段）两个方面学习胜任能力模型，不仅为招聘提供了方向，同时也可依据胜任能力模型时刻提醒自己，在纵向的各个胜任能力层次中不断提升；
5. 综合考虑胜任能力层级与工作分析可将产出的职位说明书进一步分级，根据不同级别制定不同的招聘策略，与前面课程中”招聘人员分层“也是相关联的；
疑问：在“买”的策略中，招聘时提出比较精确的工作内容和任职条件，但是相对应的候选人（或者说有意向的候选人）很少，这时如果考虑放松条件那么又不能招聘到心仪的匹配的人员，这时应该如何平衡呢？

164.36  218.33
163.96  459.5
349.75  575.39
metadata单独部署 / metadata非单独部署

2020-07-15
胜任力标准可以通过“研究-评估-应用”三步曲，其中评估阶段可使用优秀员工行为访谈（参考STAR，开放性问题），评估阶段可与标杆企业对比，应用阶段可人员甄选并调配；
以技术研发为例，学习能力、思维能力、主动性、团队协作能力、沟通能力都比较基础而且重要，在招聘期间快速识完全别候选人这些能力可能有些难度，有没有一些技巧或者方法论可以参考呢？
2020-07-16
学习到目标职位的三个关键成功因素：关键绩效指标、工作环境分析、团队未来成长要求；其中关键绩效指标是基础，取决于候选人能力也决定了候选人能否通过；工作环境（业务、文化、团队）是加成，能够帮助候选人更快融合到集体，更快产生效能；未来成长要求是终极目标，将伴随着候选人整个职业生涯；

ceph auth get-or-create client.glance -o /etc/ceph/ceph.client.glance.keyring
ceph auth get-or-create client.cinder -o /etc/ceph/ceph.client.cinder.keyring
ceph auth get-or-create client.cinder-backup -o /etc/ceph/ceph.client.cinder-backup.keyring
ceph auth get-or-create client.cinder -o client.cinder.key

[root@mecpass2 ~]# uuidgen
653a631e-6dfb-4a3f-a1c6-a55015998233
cat > secret.xml <<EOF
<secret ephemeral='no' private='no'>
  <uuid>653a631e-6dfb-4a3f-a1c6-a55015998233</uuid>
  <usage type='ceph'>
    <name>client.cinder secret</name>
  </usage>
</secret>
EOF
[root@mecpass2 ceph]# virsh secret-define secret.xml
生成 secret 653a631e-6dfb-4a3f-a1c6-a55015998233
[root@mecpass2 ceph]# virsh secret-set-value --secret 653a631e-6dfb-4a3f-a1c6-a55015998233 --base64 $(cat client.cinder.key)
secret 值设定


insert into t_app_template_name_ref (app_info_id,service_template_id,project_id,org_id,department_id,creator)     VALUES     (10,'10',10,10,10,'10')
service_template_id
666727-bb5da556-7a7d-448f-84dc-dd77687e6225
666727-a715eca4-ec36-42e8-ab45-3f4abbe91b2c-appinfo-dongcc-11-1.0/templates/configMap-config-test.yaml

2020-07-17
1. 在定义目标职位关键成功因素的基础上，通过人与人的对比可以进一步提升招聘效率，比通过内部对标来对比高绩效承担者的素质能力；
2. 刨除基本任职条件，企业喜好在一定程度上也会影响招聘过程；
3. 不定期审视组织价值“空白点”能够更快速、精确认识到企业的人才需求以及相应的紧迫程度；
阶段作业：
典型职位 -- 软件开发工程师
关键成功因素和风险点 -- 关键成功因素是工作经验和学历，风险点从两个角度出发：从应聘者的角度看，面试通过后的工作与预期相差较大（面试造火箭、工作拧螺丝），进而可能出现离职，双方造成损失；从招聘者的角度，通过面试期间可能无法全面了解应聘者的工作能力和学习能力，对之后的工作产生影响；
其他因素考量 -- 家庭因素、上班通勤时长
三个必要条件：
1. 学历要求，985/211硕士及以上；简历筛选阶段：通过学历“生硬”的筛选学习能力、思维能力相对好一些的应聘者；
2. 工作经验符合要求；面试阶段：目标职位的核心能力要求；
3. 性格测试结果；面试阶段：是否与企业文化相匹配，决定了应聘者以及企业双方能否更快更好产生化学反应；
三个淘汰条件：
1. 表达能力不强；面试阶段：能否准确、清晰的描述自身经历和面试官提出的问题；
2. 责任心不强；工作阶段：面对分配给自己的任务，应该认为自己是owner，须尽力高质量完成；
3. 学习能力不强：工作阶段：学习能力是未来成长的必要条件，面对已经出现或者未来可能出现的问题或者困难能够通过“学习”而解决，如果学习能力不强，将对双方都产生消极影响；
2020-07-18
以往工作经验中都是尽量详尽描述业务需求以及各项需求的优先级，基于此通过多个渠道（BBS发帖、内推、招聘网站等）开展招聘工作然后交由HR面试，通过今天学习到招聘顾问与业务管理者互动与洞察业务部门的真实需求，尤其是其中深度挖掘对方隐性需求（通过向其周边人员了解等）、根据交互（倾听对方、精确描述己方业务需求等）中对方反馈开展相应的行动决策，基于此如果双方抽象出一套可量化并且执行度相对较高的准则，那么共同推进招聘进程将会更有效率；
正如TED演讲中提到的，沟通过程中倾听是首要的准则，倾听是为了更好的交谈，不过个人感觉期间也要注意不能一直顺着对方的思路而丢掉自己的的立场。（这其实是写给自己的。。。）

https://mec.189.cn/gw/fs/file/download?group=mec&filename=M00/00/07/wKgAnF8U7viAGqpOAAAD59HmGsw38..tgz
https://mec.189.cn/gw/fs/file/download?group=mec&filename=M00/00/07/wKgAnF8VB7WAULB5AAAGmXI8c1c16..tgz

2020-07-20
1. 洞察业务真实需求有五个原则：知己知彼原则、需求原则、专业度原则、舍得原则、期望值原则，通过一些比较好的开放性问题能够更快的获取到所需信息，也可以用一些统计数据（包括过往招聘数据、对市场的分析）摆出事实或预测，基于数据探究真实需求；
2. 制定人力资源规划的基础是现有人力资源的信息收集与分析，包括人力资源数量、素质结构、员工潜力等等，然后预测人力资源的供求关系，最终制定人力资源的规划；
3. 招聘是方法，解决现有问题才是真正需求，很赞同老师提到的基于现有人才进行培养（可通过培训、结构化学习等方式），逐步提升人员素质、能力，不仅能完善企业自身素质结构，也降低了外部招聘的风险；
针对盘点现有人力有个疑问，单独从IT技术的角度出发，企业内不同岗位以及不同技术方向划分程度不同（有的粒度较细），人员范围也各有特色，如果想做一个现有人力资源的盘点，比如通过Excel表格的形式让大家填充自己熟悉的技术栈以及掌握程度，还有没有哪些方法或者技巧可以参考呢？

https://mec.189.cn/gw/fs/file/download?group=mec&filename=M00/00/07/wKgAnF8WgEqAWsQ_AAAGmc1NF4U89..tgz

2020-07-21
感觉颇有收获却又难以表达，惭愧！！！
以分布式存储研发工程师为例
三个关键成功因素：1. 985/211硕士及以上，优秀人员可适当放宽；2. 熟练掌握一种编程语言，Java/C/C++；3. 熟悉分布式存储原理和基础运维操作，有开发经验优先；
三个淘汰因素：1. 不了解分布式存储；2. 逻辑思维能力不强；3. 近两年跳槽次数超过3次；
目标选才公司：云厂商、设备提供商、科技公司、互联网公司
职位的销售点：1. 稳定；2. 性价比高；3. 人文关怀；4. 央企社会责任，新基建基础设施，有荣誉感
挑战与应对方案：1. 薪酬比不过互联网，但是性价比高；2. 人才流失，通过带领团队或其他方式满足其荣誉感以及精神需求

2020-07-23
现阶段了解到的招聘渠道主要有内推、网络招聘、猎头三种方式；
内推：招聘量小，命中率高；
网络招聘：筛选不精确，导致相对应的招聘工作量较大；
猎头：筛选精确而且招聘量可控，但有招聘成本；
期待后续的课程能学习到更多渠道建设的方法以及多个渠道的平衡点；

2020-07-24
招聘渠道管理是一个长期的过程，需要动态维护和激励，在众多渠道可以根据不同层次、不同岗位、不同难度分别做出相应的招聘策略；
对于频繁招聘（的岗位尤其是离职引起的），个人感觉在做好渠道建设的同时，也要挖掘其原因并针对性突出自己的优势（比如性价比、人文关怀）或者在之后的招聘中可否提供一些弥补措施等等；毕竟招到人才并且留住人才是最重要的。

2020-07-25
依托微信强大的社交属性和社交群体，公众号的确是一种很有效而且易于推广的招聘方式；
除了自运营公众号方式之外，针对特定专业性人才可以在其相关专业官方授权的公众号挂载招聘需求（很多官方公众号提供招聘功能），这样能够在相关专业圈内招聘到相对更专业的候选人；

dmesg 
dmsetup

1.	关于试点，建议增加一个商超综合体的省公司试点
关于省公司试点我们可以宣传推广，因为涉及到硬件资源、机房等一系列基础设施问题，现阶段已沟通协商为主；
2.	5G绽放杯目前进展，确定intel参与方式及工作内容
与悉见科技相关人员确认，现阶段基于Cuda工具包提供渲染能力，如果使用Intel相关加速、渲染相关技术则需要改造架构和程序，而且绽放杯相关文档须于2020-07-31前提交，鉴于改造工作量大以及文档周期紧张，建议下次再引入OpenVino等技术共同参与；
3.	明确白皮书时间计划，因为需要提前准备相关资源
白皮书预计今年完成（初步计划是在10月底左右），具体内容根据实际测试阶段和结果再详细商议；


·         讨论：第三方云对接接口，包括天翼云或其他第三方云，相当于业务管理平台中云边协同的模块，通过调用业务管理平台的Open API部署应用到边缘节点
·         行动点：
o    对象存储云边协同能力化，以能力形式输出，不能只是云存储，其他业务的引入；
o    对象存储云边协同作为MEC业务管理平台的功能对外开放，存储协同作为MEP的一个能力，本部分工作需要与架构团队、业务管理平台团队和MEP团队紧密合作。
o    块存储暂不支持能力化
o    下周出具体工作及产出计划。


radosgw-admin user create --uid="cephrgwuser" --display-name="cephrgwuser" --access-key="" --secret-key=""

表1 - mec_user_ref MEC节点与普通用户关联关系表
自增主键-MEC节点编码-MEC节点名称-用户ID-用户Name-accesskey-secretkey-创建时间-更新时间
表2 - mec_bucket_ref MEC节点与用户桶关联关系表
自增主键-MEC节点编码-用户ID-bucketname-创建时间-更新时间
表3 - mec_manage_ref MEC节点与管理信息关联关系表
自增主键-MEC节点编码-MEC节点名称-rgw管理员用户ID-rgw管理员用户Name-rgw管理员用户accesskey-rgw管理员用户secretkey-分发网关服务地址IP-分发网关服务地址端口-httptokafka服务地址ip-httptokafka服务地址端口

15117946727

docker run --name nginx -p 8082:8082 -p 11808:11808 -p 13808:13808 -p 18088:18088 -v /usr/local/openresty/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/docker-nginx/logs:/usr/local/openresty/nginx/logs -v /home/docker-nginx/logs:/etc/nginx/logs -d nginx:1.19

一、AI协同：（云端和边缘均需要有执行模型的环境/平台，不同模型对应的结构化数据不一样）
0. 云端训练，特征下发到边缘，即边缘分析、云端训练；
1. 边缘和云端均有模型：边缘预处理，将结构化数据发送到云端，由云端最终处理；
2. 边缘没有模型、云端有模型：边缘提取特征，将结构化数据发送到云端，由云端分析；


一、AI协同：（云端和边缘均需要有执行模型的环境/平台，不同模型对应的结构化数据不一样）
0. 云端训练，特征【模型】下发到边缘，即边缘分析、云端训练；
1. 边缘和云端均有模型：边缘【小模型】预处理，将结构化数据发送到云端，由云端【大模型】最终处理；
2. 边缘没有模型、云端有模型【类似于现有云计算的方式】：
边缘提取特征【不走模型，纯代码处理逻辑】，将结构化数据发送到云端，由云端分析【汇总】；
二、数据协同：
1. 海量数据没必要全部发送到云端，提取部分必要的数据再发送到云端；（业务数据，与实际业务相关性很强，较大难度整理统一接口）
2. 边缘节点中应用日志，全量同步到云端，边缘只保留部分；（视情况而定）
3. 边缘业务数据保留近几天，云端保留全部；（业务数据，与实际业务相关性很强，较大难度整理统一接口）
4. 原始数据价值较低，流数据分析可先对数据进行清洗、加工、聚合之后再上云，大大减少数据传输成本；（不同业务数据的清洗、加工、聚合策略不一样）
5. 数据在边缘节点进行有效收敛、AI及结构化处理，关键性数据再回传到中心云；（不同业务的关键性数据不一样）
6. 数据清洗，机器学习，非隐私数据清洗汇总后，上传云端机器学习，持续优化本地智能算法
三、应用协同：
1. 第三方云通过调用接口将其应用/能力下发到边缘；（梳理流程，整合业务管理平台相关接口，也可由业务管理平台完成）
四、对象存储协同：
1. 视频监控边缘加速（与福富结合）
2. 点播/直播加速（与奎哥沟通）
3. 视频/图片数据结合智能AI分析；

http请求接口 50-60ms
mybatis物理查询/逻辑查询
java线程池
Java进程100%

ceph rgw管理员accesskey-secretkey、ceph rgw地址和端口、kafka、mysql
anglar js
maven helper


(1) 对技术问题有清晰的分析逻辑和全局思维，能提出具有创造性的解决思路和方案
(2) 3年以上的软件开发经历，负责过独立功能或模块的设计和代码实现，具备软件开发流程（需求、设计、开发、持续集成、测试、文档、发布、更新维护等）的实践经验
(3) 精通java语言，熟悉Java技术栈常用开源框架（spring，spring boot, myBatis, dubbo等），熟练使用数据库mysql，缓存redis等
(4) 熟悉Linux常用命令

Java开发工程师/高级Java开发工程师
1. 研究生学历及以上，3年工作经验;
1. 具备扎实的Java基础，熟悉常用数据结构、JVM基本原理、并发编程等;
2. 熟悉常用的中间件，如 dubbo，消息队列，流程引擎，规则引擎;
3. 熟悉常用设计模式，掌握Spring、SpringBoot、MyBatis、SpirngMVC、Dubbo、VUE等技术;
4. 熟悉 Mysql，对事务，分库分表，性能优化等数据库的基本技能;
5. 熟悉Tomcat、Jetty、Nginx等服务器配置使用;
6. 熟悉Linux常用命令;
7. 对技术问题有清晰的分析逻辑和全局思维，做事积极主动，具有高度的责任感与团队合作精神，有良好的沟通能力;

https://docs.ceph.com/docs/nautilus/rados/operations/cache-tiering/
https://docs.ceph.com/docs/nautilus/radosgw/sync-modules/

http://gitlab.tech.5gcen.com:9088/newmec/meom.git


yum remove python-rbd
yum remove librbd1
yum remove python-ceph-argparse
 yum remove librados2
 yum remove libradosstriper1
 yum remove python-rgw
 yum remove libcephfs2
  yum remove librados2
  yum remove librados2
yum remove python-rados
yum remove librgw2
yum remove python-cephfs
yum remove libcephfs2


radosgw-admin user create --uid="ctyunoos" --display-name="ctyunoos-rongheban" --access-key="9VEywrsJz2MTZ6qjuREj" --secret-key="CxsDTYUN6WctSiELxpuwCbpT0c5TQiDcZKt6Jh6U"

radosgw-admin user create --uid=adminuser --display-name=adminuser --system
gs-mep adminuser CEZZ29FJHYIH4P9TQ887 ceoFMVVmyxmWKD54Ly9MmVnXyB4NwXiVVrNcqO3q

江苏涉及到存储，65T不够，江苏高丽华、杨基明、杨鑫所了解

天翼云充值
一、天翼云经典版分线上账号和线下账号：
1.1 线上账号-预付费：注册+开通产品，使用产品，记录容量、流量，从余额中扣费（前提是余额中有钱，充过值）；
1.2 线下账号-后付费：找相应的项目经理，项目经理提供账单，后付费；
二、天翼云融合版是按容量包年包月的方式申请，超出相应容量不可使用；

1.1 预付费方式，由MEC收取费用（包含云端容量费用+流量费用），MEC充值到天翼云账户余额；
1.2 预付费方式，由用户分别在MEC平台购买资源、在天翼云账户余额充值；
1.3 后付费方式，由MEC收取费用（包含云端容量费用+流量费用），MEC根据账单付费；
1.4 包年包月方式，与MEC方式一致，由MEC收取云端相应费用，付费到云端；

完成ceph集群剩余容量接口的开发，完成部分融合接口（用户创建、桶创建）的修改，完成甘肃节点Ceph版本升级，完成对象存储云边协同应用部署，正与万维云胶片应用联调测试，整体完成9.30工作目标40%；
1048576
5242880

{"accessKey":"26ef4197c754a80d590c","secretKey":"629ccbf9cd6144b64dad8abdf05b1d8c5091c0d5","host":"127.0.0.1","port":"8082","originalRequestBody":"","resourcePath":"/mytest","method":"PUT","requestHeads":"","requestParameters":""}

cd existing_folder
git init
git remote add origin http://gitlab.tech.5gcen.com:9088/eos-server/oss_portal.git
git add .
git commit -m "Initial commit"
git push -u origin master

git remote add origin http://gitlab.tech.5gcen.com:9088/eos-server/httptokafka.git

分布式锁
数据一致性，数据库怎么实现？
局部最优？
内存调优
性能调优
kafka顺序性
Netty事件模型
索引
数据库锁、事务隔离级别

已完成甘肃节点边缘对象存储升级工作
已完成云边协同应用部署工作，支撑公网https访问
已完成与云胶片应用功能测试

注：甘肃节点资源（磁盘和带宽）问题已发送邮件说明


addauth digest gs-user:gspswrd
setAcl /path auth:gs-user:gspswrd:cdrwa
getAcl /path

systemctl start sshd
echo 'start sshd'..$?
systemctl start sshd.socket
echo 'start sshd.socket'..$?
systemctl start sshd.service
echo 'start sshd.service'..$?


iPtgMMKaZSzdN47TZn2h
zAA11c2EshPMYaOx61N7
7ksEr1lNxpWi4E7CZrJe
FtIGXQ6w54ROpx6nOZgP
m9AbUUo9eYKW8K9NRjgo

1.ceph部署在物理机，网络隔离，但是要求需要存储的应用/数据库等能够访问ceph（网络）；
2.集成公司对这种方案的支撑程度需要确认，按之前的了解（甘肃节点）集成公司不建议openstack+ceph；


./csi-rbdplugin-provisioner.yaml:          image: quay.io/k8scsi/csi-provisioner:v1.3.0
./csi-rbdplugin-provisioner.yaml:          image: quay.io/k8scsi/csi-snapshotter:v1.1.0
./csi-rbdplugin-provisioner.yaml:          image: quay.io/k8scsi/csi-attacher:v1.2.0
./csi-rbdplugin-provisioner.yaml:          image: quay.io/cephcsi/cephcsi:v1.2.2
./csi-rbdplugin-provisioner.yaml:          image: quay.io/cephcsi/cephcsi:v1.2.2
./csi-rbdplugin.yaml:          image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0
./csi-rbdplugin.yaml:          image: quay.io/cephcsi/cephcsi:v1.2.2
./csi-rbdplugin.yaml:          image: quay.io/cephcsi/cephcsi:v1.2.2

quay.io/k8scsi/csi-provisioner:v1.3.0
quay.io/k8scsi/csi-snapshotter:v1.1.0
quay.io/k8scsi/csi-attacher:v1.2.0
quay.io/cephcsi/cephcsi:v1.2.2
quay.io/k8scsi/csi-node-driver-registrar:v1.1.0


image: quay.io/k8scsi/csi-provisioner:v1.3.0
image: quay.io/k8scsi/csi-attacher:v1.2.0
image: quay.io/cephcsi/cephcsi:v1.2.2
image: quay.io/cephcsi/cephcsi:v1.2.2
image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0
image: quay.io/cephcsi/cephcsi:v1.2.2
image: quay.io/cephcsi/cephcsi:v1.2.2

docker pull  harbor.mec189.cn:30443/5gmec/csi-provisioner:v1.3.0
docker pull  harbor.mec189.cn:30443/5gmec/csi-snapshotter:v1.1.0
docker pull harbor.mec189.cn:30443/5gmec/csi-attacher:v1.2.0
docker pull  harbor.mec189.cn:30443/5gmec/cephcsi:v1.2.2
docker pull  harbor.mec189.cn:30443/5gmec/csi-node-driver-registrar:v1.1.0

1. MEO&MEPM：MEPM鉴权；
2. 业务管理平台：获取用户边缘节点、生成存储容量订单、生成流量包订单、生成请求次数订单、短信通知？；
3. 天翼云：单个桶的存储用量、创建Bucket时如何确定使用哪个location、云端用户桶内所有数据；
4. MEP：上报流量话单，涉及MEPM+MEO+运营；


截图
工单邮箱是miaohai@chinatelecom.cn，
MEC商用项目，甘肃节点6台物理机磁盘空间不足，申请磁盘扩容80T，300M带宽，请转到运维VIP经理孙博、李超

流媒体收集服务，将对端(监控摄像头)上流媒体进行收集&转码&存储，数据格式统一交付给后端；
云边协同服务，支持近期数据快速存储、访问，具备数据加速能力，提升数据存储效率，降低延迟；
公有云数据存储服务，提供全量数据存储；

以史为镜，可以知兴替，以人为镜，可以知得失；今天上午反腐倡廉教育收获很大，通过警示教育提高了本人思想道德素质，锻炼了党性，增强了法制观念和纪律意识，尤其是在加强自身学习的同时观看反面案例警示教育，在自己思想深处受到极大触动；我们应该时刻牢记“实事求是”的重要思想，站好自己的位置，认清现有的问题，明确自己的任务，加强学习和修养，警钟长鸣；

ChengDu、FuZhou、GuiYang、HangZhou、LaSa、LanZhou、QingDao、ShenYang、ShenZhen、WuHan、WuHu、WuLuMuQi、ZhengZhou
ChengDu、GuiYang、LaSa、LanZhou、QingDao、SH2、ShenYang、ShenZhen、SuZhou、WuHan、WuHu、WuLuMuQi、ZhengZhou
ChengDu、GuiYang、LaSa、LanZhou、QingDao、ShenYang、ShenZhen、WuHan、WuHu、WuLuMuQi、ZhengZhou
200063 - 产品管理
200064 - 存储产品管理
200065 - 云边对象存储
200066 - 资源概览
200067 - 数据桶列表
200068 - 资源包管理
200069 - 安全管理

1、当前进展
准备接口文档已完成；
开发/调整演示页面后台程序，已完成20%
2、下周计划
开发/调整演示页面后台程序
3、遇到的问题及拟解决方案
无

%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8
%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8
%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8

nginx%20-%20%E5%89%AF%E6%9C%AC%20%2818%29.pid
nginx%20-%20%E5%89%AF%E6%9C%AC%20(18).pid
nginx - 副本 (18).pid

32EYJ0SDN9HQN5ZF842J  xE3quHq1F8fLgw6ZjMKUhyOGw0k72XHV0PUQ9JVm
32EYJ0SDN9HQN5ZF842J  xE3quHq1F8fLgw6ZjMKUhyOGw0k72XHV0PUQ9JVm

2NAYHEX0TI4FYP7KVSDP  daO8S9UHEsNcIpcWJrMn1b4p080e0dEMIlyjLVDO
2NAYHEX0TI4FYP7KVSDP  daO8S9UHEsNcIpcWJrMn1b4p080e0dEMIlyjLVDO

1、当前进展
开发/调整演示页面后台程序，已完成70%
2、下周计划
开发/调整演示页面后台程序，联调测试
3、遇到的问题及拟解决方案
无

export http_proxy=http://124.127.117.154:3128
export https_proxy=http://124.127.117.154:3128
export no_proxy='127.0.0.1'

nginx%2520-%2520%25E5%2589%25AF%25E6%259C%25AC%2520%25288%2529.pid
nginx%20-%20%E5%89%AF%E6%9C%AC%20%2818%29.pid
bucket/1%20-%20%E5%89%AF%E6%9C%AC%20%2823%29.txt


/dong3/nginx%20-%20%E5%89%AF%E6%9C%AC%20%2812%29.pid
/dong3/nginx%20-%20%E5%89%AF%E6%9C%AC%20%2812%29.pid

IGCQRMKEQDENJY7J62SX
ZX5GHKZNS33ZEAJFQ1X5

1. eos-management
MYSQL_HOST  172.16.245.42
MYSQL_PORT  3306
MYSQL_USER  root
MYSQL_PASSWORD  1qaz@WSX
REDIS_HOST  172.16.245.42
REDIS_PORT  6379
REDIS_PWD  1qaz@WSX
MERM_URL_ROOT  mec-merm:8336
OMS_URL_ROOT  mec-oms-tc:8074
CLOUD_PROXY_HOST  172.16.245.46
CLOUD_PROXY_PORT  3128

2. httptokafka --- harbor.dev.com:31680/eos/htk:init
ZK_HOST  172.16.245.212
ZK_PORT  2181
KAFKA_HOST  172.16.245.212
KAFKA_PORT  9092

3. eos-metering --- harbor.dev.com:31680/eos/met:init
MYSQL_HOST  172.16.245.42
MYSQL_PORT  3306
MYSQL_USER  root
MYSQL_PASSWORD  1qaz@WSX
REDIS_HOST  172.16.245.42
REDIS_PORT  6379
REDIS_PWD  1qaz@WSX
KAFKA_HOST  172.16.245.212
KAFKA_PORT  9092

4. eos-sync --- harbor.dev.com:31680/eos/syn:init
MYSQL_HOST  172.16.245.42
MYSQL_PORT  3306
MYSQL_USER  root
MYSQL_PASSWORD  1qaz@WSX
REDIS_HOST  172.16.245.42
REDIS_PORT  6379
REDIS_PWD  1qaz@WSX
KAFKA_HOST  172.16.245.212
KAFKA_PORT  9092
EDGE_HOST  172.16.245.46
EDGE_PORT  7480

5. dispatchingsystem --- harbor.dev.com:31680/eos/dis:init
MYSQL_HOST  172.16.245.42
MYSQL_PORT  3306
MYSQL_USER  root
MYSQL_PASSWORD  1qaz@WSX
REDIS_HOST  172.16.245.42
REDIS_PORT  6379
REDIS_PWD  1qaz@WSX
KAFKA_HOST  172.16.245.212
KAFKA_PORT  9092
EDGE_HOST  172.16.245.46
EDGE_PORT  7480
CLOUD_TYPE  ctyun
ADMIN_ACCESS_KEY  xxx
ADMIN_SECRET_KEY  yyy
FAILED_USER_PATH  /data/dispatcheringsystem/faileduser
CLOUD_RESPONSE_PATH  /data/dispatcheringsystem/cloudresponsepath


docker load -i eos-management-v1.tar
docker tag eos-management:v1 harbor.dev.com:31680/mec151/eos:init
docker push harbor.dev.com:31680/mec151/eos:init

radosgw-admin user create --uid=manager --display-name=manager --access-key=IGCQRMKEQDENJY7J62SX  --secret-key=lmeC54roJjl0AkLZM5JKclRjaa8zGm1qPxRoHv69  --system

bin/kafka-topics.sh --create --topic k8s-accounting-info --bootstrap-server localhost:9092

1、当前进展
开发/调整演示页面后台程序，已完成
联调测试，研发中心领导演示
2、下周计划
联调测试，研发中心领导演示
3、遇到的问题及拟解决方案
无
1、当前进展
联调测试，研发中心领导演示
2、下周计划
联调测试
3、遇到的问题及拟解决方案
无

harbor.dev.com:31680/eos/dis
harbor.dev.com:31680/eos/htk
harbor.dev.com:31680/eos/met
harbor.dev.com:31680/eos/syn

Java开发工程师/高级Java开发工程师
1. 研究生学历及以上，3年工作经验;
2. 具备扎实的Java基础，熟悉常用数据结构、JVM基本原理、并发编程等;
3. 熟悉常用的中间件，如 dubbo，消息队列，流程引擎，规则引擎;
4. 熟悉常用设计模式，掌握Spring、SpringBoot、MyBatis、SpirngMVC、Dubbo、VUE等技术;
5. 熟悉 Mysql，对事务，分库分表，性能优化等数据库的基本技能;
6. 熟悉Tomcat、Jetty、Nginx等服务器配置使用,熟悉Linux常用命令;
7. 对技术问题有清晰的分析逻辑和全局思维，做事积极主动，具有高度的责任感与团队合作精神，有良好的沟通能力;
边缘云研发工程师
1. 研究生学历及以上，3年工作经验，熟悉云原生技术;
2. 熟练掌握Java/C/C++/Go至少一种编程语言，熟悉使用Shell/pathon脚本语言，深刻理解边缘计算、云边协同等;
3. 熟练掌握Kubernetes、Docker，熟悉Kubernetes相关生态，Prometheus、Ingress、Service、CSI、Harbor等;
4. 具有边缘计算系统研发经验者优先，有容器PaaS平台开发经验者优先，熟悉并拥有OpenStack实操经验者优先;
5. 具备良好的分析解决问题能力，熟悉Linux常用命令;
6. 对技术问题有清晰的分析逻辑和全局思维，做事积极主动，具有高度的责任感与团队合作精神，有良好的沟通能力;